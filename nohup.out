Start running the experiment.
>>>> [CUDA]Cuda visible devices: 7
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `1`
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
[04/16/25 23:28:27] INFO     Loading model in int8: False   finetuned_llms.py:95
                             or half: True                                      
[04/16/25 23:28:28] INFO     > Loading the provided        finetuned_llms.py:113
                             ./ft_llms/Qwen/Qwen2.5-0.5B/a                      
                             g_news/bs32/target_base/check                      
                             point-460 checkpoint from                          
                             './ft_llms/Qwen/Qwen2.5-0.5B/                      
                             ag_news/bs32/target_base/chec                      
                             kpoint-460'.                                       
[04/16/25 23:29:13] INFO     Train dataset columns: ['text',     provider.py:149
                             'label'], select text column: text                 
                    INFO     Block size: 32, max buffer size:    provider.py:162
                             117964.8                                           
[04/16/25 23:29:13] INFO     Using split dataset.                  factory.py:35
Computing length of the text(train):   0%|          | 0/3000 [00:00<?, ? examples/s]Computing length of the text(train):  56%|█████▌    | 1686/3000 [00:00<00:00, 16738.46 examples/s]Computing length of the text(train): 100%|██████████| 3000/3000 [00:01<00:00, 2962.03 examples/s] 
Computing length of the text(test):   0%|          | 0/2000 [00:00<?, ? examples/s]Computing length of the text(test):  69%|██████▉   | 1378/2000 [00:00<00:00, 13686.75 examples/s]Computing length of the text(test): 100%|██████████| 2000/2000 [00:00<00:00, 10289.25 examples/s]
[04/16/25 23:29:14] INFO     Average Length of the string in           run.py:20
                             dataset:(144.44433333333333, 142.3665)             
                    INFO     Data preview: {'text': ' with India to    run.py:21
                             advance a peace process that has faltered          
                             recently over Kashmir, while a more                
                             reserved India said progress must be               
                             measured "step-by-step".Car Bomb'}                 
                             {'text': ' Anthrax Vaccine (Reuters)               
                             Reuters - California vaccine maker VaxGen          
                             Inc.\\will make a new and improved                 
                             version of the anthrax vaccine for\\use            
                             in'}                                               
[04/16/25 23:29:15] INFO     Loading model in int8: False   finetuned_llms.py:95
                             or half: True                                      
                    INFO     > Loading the provided        finetuned_llms.py:113
                             ./ft_llms/Qwen/Qwen2.5-0.5B/a                      
                             g_news/bs32/self_prompt/check                      
                             point-28 checkpoint from                           
                             './ft_llms/Qwen/Qwen2.5-0.5B/                      
                             ag_news/bs32/self_prompt/chec                      
                             kpoint-28'.                                        
If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`
[04/16/25 23:29:32] INFO     Evaluating train set:                    MIA.py:140
Evaluating spv_mia:   0%|          | 0/3000 [00:00<?, ? examples/s]Evaluating spv_mia:   2%|▏         | 64/3000 [00:58<44:41,  1.09 examples/s]Evaluating spv_mia:   4%|▍         | 128/3000 [02:00<45:21,  1.06 examples/s]Evaluating spv_mia:   6%|▋         | 192/3000 [02:27<33:00,  1.42 examples/s]Evaluating spv_mia:   9%|▊         | 256/3000 [02:50<26:09,  1.75 examples/s]Evaluating spv_mia:  11%|█         | 320/3000 [03:13<22:06,  2.02 examples/s]Evaluating spv_mia:  13%|█▎        | 384/3000 [03:39<20:11,  2.16 examples/s]Evaluating spv_mia:  15%|█▍        | 448/3000 [04:02<18:20,  2.32 examples/s]Evaluating spv_mia:  17%|█▋        | 512/3000 [04:26<17:03,  2.43 examples/s]Evaluating spv_mia:  19%|█▉        | 576/3000 [04:48<15:50,  2.55 examples/s]Evaluating spv_mia:  21%|██▏       | 640/3000 [05:09<14:30,  2.71 examples/s]Evaluating spv_mia:  23%|██▎       | 704/3000 [05:34<14:26,  2.65 examples/s]Evaluating spv_mia:  26%|██▌       | 768/3000 [05:57<13:50,  2.69 examples/s]Evaluating spv_mia:  28%|██▊       | 832/3000 [06:25<14:05,  2.56 examples/s]Evaluating spv_mia:  30%|██▉       | 896/3000 [06:51<13:50,  2.53 examples/s]Evaluating spv_mia:  32%|███▏      | 960/3000 [07:13<12:53,  2.64 examples/s]Evaluating spv_mia:  34%|███▍      | 1024/3000 [07:38<12:41,  2.60 examples/s]Evaluating spv_mia:  36%|███▋      | 1088/3000 [08:01<11:57,  2.67 examples/s]Evaluating spv_mia:  38%|███▊      | 1152/3000 [08:24<11:24,  2.70 examples/s]Evaluating spv_mia:  41%|████      | 1216/3000 [08:46<10:49,  2.75 examples/s]Evaluating spv_mia:  43%|████▎     | 1280/3000 [09:10<10:29,  2.73 examples/s]Evaluating spv_mia:  45%|████▍     | 1344/3000 [09:28<09:30,  2.90 examples/s]Evaluating spv_mia:  47%|████▋     | 1408/3000 [09:51<09:09,  2.90 examples/s]Evaluating spv_mia:  49%|████▉     | 1472/3000 [10:15<09:00,  2.83 examples/s]Evaluating spv_mia:  51%|█████     | 1536/3000 [10:38<08:45,  2.79 examples/s]Evaluating spv_mia:  53%|█████▎    | 1600/3000 [11:03<08:35,  2.71 examples/s]Evaluating spv_mia:  55%|█████▌    | 1664/3000 [11:23<07:45,  2.87 examples/s]Evaluating spv_mia:  58%|█████▊    | 1728/3000 [11:47<07:34,  2.80 examples/s]Evaluating spv_mia:  60%|█████▉    | 1792/3000 [12:12<07:26,  2.71 examples/s]Evaluating spv_mia:  62%|██████▏   | 1856/3000 [12:36<07:03,  2.70 examples/s]Evaluating spv_mia:  64%|██████▍   | 1920/3000 [13:00<06:42,  2.68 examples/s]Evaluating spv_mia:  66%|██████▌   | 1984/3000 [13:22<06:09,  2.75 examples/s]Evaluating spv_mia:  68%|██████▊   | 2048/3000 [13:46<05:47,  2.74 examples/s]Evaluating spv_mia:  70%|███████   | 2112/3000 [14:11<05:30,  2.68 examples/s]Evaluating spv_mia:  73%|███████▎  | 2176/3000 [14:34<05:03,  2.72 examples/s]Evaluating spv_mia:  75%|███████▍  | 2240/3000 [14:56<04:34,  2.77 examples/s]Evaluating spv_mia:  77%|███████▋  | 2304/3000 [15:20<04:13,  2.74 examples/s]Evaluating spv_mia:  79%|███████▉  | 2368/3000 [15:44<03:53,  2.71 examples/s]Evaluating spv_mia:  81%|████████  | 2432/3000 [16:08<03:31,  2.69 examples/s]Evaluating spv_mia:  83%|████████▎ | 2496/3000 [16:31<03:05,  2.72 examples/s]Evaluating spv_mia:  85%|████████▌ | 2560/3000 [16:55<02:41,  2.72 examples/s]Evaluating spv_mia:  87%|████████▋ | 2624/3000 [17:14<02:11,  2.85 examples/s]Evaluating spv_mia:  90%|████████▉ | 2688/3000 [17:41<01:55,  2.71 examples/s]Evaluating spv_mia:  92%|█████████▏| 2752/3000 [18:05<01:31,  2.70 examples/s]Evaluating spv_mia:  94%|█████████▍| 2816/3000 [18:34<01:12,  2.53 examples/s]Evaluating spv_mia:  96%|█████████▌| 2880/3000 [19:05<00:50,  2.37 examples/s]Evaluating spv_mia:  98%|█████████▊| 2944/3000 [19:32<00:23,  2.37 examples/s]Evaluating spv_mia: 100%|██████████| 3000/3000 [19:55<00:00,  2.39 examples/s]Evaluating spv_mia: 100%|██████████| 3000/3000 [19:55<00:00,  2.51 examples/s]
[04/16/25 23:49:47] INFO     Train avg score: -1.4826709637294213     MIA.py:144
                    INFO     Evaluating test set:                     MIA.py:155
Evaluating spv_mia:   0%|          | 0/2000 [00:00<?, ? examples/s]Evaluating spv_mia:   3%|▎         | 64/2000 [00:22<11:26,  2.82 examples/s]Evaluating spv_mia:   6%|▋         | 128/2000 [00:46<11:18,  2.76 examples/s]Evaluating spv_mia:  10%|▉         | 192/2000 [01:09<10:55,  2.76 examples/s]Evaluating spv_mia:  13%|█▎        | 256/2000 [01:33<10:43,  2.71 examples/s]Evaluating spv_mia:  16%|█▌        | 320/2000 [01:56<10:09,  2.76 examples/s]Evaluating spv_mia:  19%|█▉        | 384/2000 [02:16<09:20,  2.88 examples/s]Evaluating spv_mia:  22%|██▏       | 448/2000 [02:40<09:14,  2.80 examples/s]Evaluating spv_mia:  26%|██▌       | 512/2000 [03:01<08:32,  2.90 examples/s]Evaluating spv_mia:  29%|██▉       | 576/2000 [03:25<08:29,  2.79 examples/s]Evaluating spv_mia:  32%|███▏      | 640/2000 [03:48<08:08,  2.79 examples/s]Evaluating spv_mia:  35%|███▌      | 704/2000 [04:12<07:49,  2.76 examples/s]Evaluating spv_mia:  38%|███▊      | 768/2000 [04:37<07:35,  2.70 examples/s]Evaluating spv_mia:  42%|████▏     | 832/2000 [05:00<07:07,  2.73 examples/s]Evaluating spv_mia:  45%|████▍     | 896/2000 [05:22<06:38,  2.77 examples/s]Evaluating spv_mia:  48%|████▊     | 960/2000 [05:46<06:18,  2.75 examples/s]Evaluating spv_mia:  51%|█████     | 1024/2000 [06:09<05:56,  2.74 examples/s]Evaluating spv_mia:  54%|█████▍    | 1088/2000 [06:35<05:41,  2.67 examples/s]Evaluating spv_mia:  58%|█████▊    | 1152/2000 [06:57<05:10,  2.73 examples/s]Evaluating spv_mia:  61%|██████    | 1216/2000 [07:20<04:45,  2.74 examples/s]Evaluating spv_mia:  64%|██████▍   | 1280/2000 [07:46<04:29,  2.67 examples/s]Evaluating spv_mia:  67%|██████▋   | 1344/2000 [08:06<03:53,  2.80 examples/s]Evaluating spv_mia:  70%|███████   | 1408/2000 [08:30<03:34,  2.76 examples/s]Evaluating spv_mia:  74%|███████▎  | 1472/2000 [08:49<03:01,  2.91 examples/s]Evaluating spv_mia:  77%|███████▋  | 1536/2000 [09:12<02:41,  2.87 examples/s]Evaluating spv_mia:  80%|████████  | 1600/2000 [09:41<02:32,  2.62 examples/s]Evaluating spv_mia:  83%|████████▎ | 1664/2000 [10:08<02:12,  2.54 examples/s]Evaluating spv_mia:  86%|████████▋ | 1728/2000 [10:37<01:51,  2.45 examples/s]Evaluating spv_mia:  90%|████████▉ | 1792/2000 [10:56<01:18,  2.64 examples/s]Evaluating spv_mia:  93%|█████████▎| 1856/2000 [11:19<00:53,  2.70 examples/s]Evaluating spv_mia:  96%|█████████▌| 1920/2000 [11:44<00:30,  2.65 examples/s]Evaluating spv_mia:  99%|█████████▉| 1984/2000 [12:04<00:05,  2.80 examples/s]Evaluating spv_mia: 100%|██████████| 2000/2000 [12:12<00:00,  2.70 examples/s]Evaluating spv_mia: 100%|██████████| 2000/2000 [12:12<00:00,  2.73 examples/s]
[04/17/25 00:02:16] INFO     Test avg score: -0.6912140929475427      MIA.py:160
Saving the dataset (0/1 shards):   0%|          | 0/3000 [00:00<?, ? examples/s]Saving the dataset (1/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 30898.48 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 30076.47 examples/s]
Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]Saving the dataset (1/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 35094.81 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 33490.93 examples/s]
[04/17/25 00:02:17] INFO     Neighbor data saved to                   MIA.py:279
                             ./data/neighbor_data/Qwen2TokenizerFast/           
                             ag_news/bs32/spv_mia                               
[04/17/25 00:02:18] INFO     =========ENDING==========                 run.py:41
                    INFO                                             0 run.py:42
                             block_size                             32          
                             metric                            spv_mia          
                             train_score                     -1.482671          
                             test_score                      -0.691214          
                             acc                                 0.833          
                             auc                              0.951123          
                             TPR@0.1%FPR(0.00100)             0.012667          
                             TPR@0.5%FPR(0.00500)             0.014667          
                             TPR@1.0%FPR(0.01000)             0.023333          
                             TPR@5.0%FPR(0.05000)             0.736667          
                             FPR@99.0%TPR(0.99000)              0.2355          
                             FPR@95.0%TPR(0.95000)                0.12          
                             n_perturbed                            50          
                             n_neighbor                             25          
                             mask_ratio                            0.2          
                             refer_model              Qwen2ForCausalLM          
                             mask_model             RobertaForCausalLM          
                    INFO     Total time: 2031.2 seconds                run.py:45
Start running the experiment.
>>>> [CUDA]Cuda visible devices: 7
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `1`
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
[04/17/25 00:02:40] INFO     Loading model in int8: False   finetuned_llms.py:95
                             or half: True                                      
                    INFO     > Loading the provided        finetuned_llms.py:113
                             ./ft_llms/Qwen/Qwen2.5-0.5B/a                      
                             g_news/bs64/target_base/check                      
                             point-276 checkpoint from                          
                             './ft_llms/Qwen/Qwen2.5-0.5B/                      
                             ag_news/bs64/target_base/chec                      
                             kpoint-276'.                                       
[04/17/25 00:02:53] INFO     Train dataset columns: ['text',     provider.py:149
                             'label'], select text column: text                 
                    INFO     Block size: 64, max buffer size:    provider.py:162
                             235929.6                                           
[04/17/25 00:02:53] INFO     Using split dataset.                  factory.py:35
Computing length of the text(train):   0%|          | 0/3000 [00:00<?, ? examples/s]Computing length of the text(train):  65%|██████▍   | 1946/3000 [00:00<00:00, 19360.73 examples/s]Computing length of the text(train): 100%|██████████| 3000/3000 [00:00<00:00, 14699.65 examples/s]
Computing length of the text(test):   0%|          | 0/2000 [00:00<?, ? examples/s]Computing length of the text(test):  98%|█████████▊| 1951/2000 [00:00<00:00, 19406.93 examples/s]Computing length of the text(test): 100%|██████████| 2000/2000 [00:00<00:00, 16235.31 examples/s]
[04/17/25 00:02:54] INFO     Average Length of the string in           run.py:20
                             dataset:(285.97833333333335, 283.5965)             
                    INFO     Data preview: {'text': ' Hamadeh was      run.py:21
                             wounded Friday when his car was targeted           
                             by a remote-controlled bomb near his               
                             home. He suffered only minor injuries,             
                             but his driver was killed and a bodyguard          
                             was seriously hurt.PeopleSoft Ousts CEO            
                             Who Battled Oracle  In NEW YORK story              
                             headlined "PeopleSoft ousts CEO amid '}            
                             {'text': " anger A computer firm is                
                             criticised by the Kennedy family for               
                             producing a game recreating the                    
                             president's death.PeopleSoft Won #39;t Go          
                             Quietly A major battle is over, but the            
                             war for PeopleSoft (PSFT:Nasdaq - news -           
                             research) rages on. Executives of the              
                             business"}                                         
                    INFO     Loading model in int8: False   finetuned_llms.py:95
                             or half: True                                      
                    INFO     > Loading the provided        finetuned_llms.py:113
                             ./ft_llms/Qwen/Qwen2.5-0.5B/a                      
                             g_news/bs64/self_prompt/check                      
                             point-28 checkpoint from                           
                             './ft_llms/Qwen/Qwen2.5-0.5B/                      
                             ag_news/bs64/self_prompt/chec                      
                             kpoint-28'.                                        
If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`
[04/17/25 00:02:58] INFO     Evaluating train set:                    MIA.py:140
Evaluating spv_mia:   0%|          | 0/3000 [00:00<?, ? examples/s]Evaluating spv_mia:   2%|▏         | 64/3000 [00:21<16:16,  3.01 examples/s]Evaluating spv_mia:   4%|▍         | 128/3000 [00:41<15:22,  3.11 examples/s]Evaluating spv_mia:   6%|▋         | 192/3000 [01:01<14:49,  3.16 examples/s]Evaluating spv_mia:   9%|▊         | 256/3000 [01:23<14:55,  3.06 examples/s]Evaluating spv_mia:  11%|█         | 320/3000 [01:43<14:28,  3.09 examples/s]Evaluating spv_mia:  13%|█▎        | 384/3000 [02:05<14:23,  3.03 examples/s]Evaluating spv_mia:  15%|█▍        | 448/3000 [02:27<14:16,  2.98 examples/s]Evaluating spv_mia:  17%|█▋        | 512/3000 [02:46<13:27,  3.08 examples/s]Evaluating spv_mia:  19%|█▉        | 576/3000 [03:08<13:11,  3.06 examples/s]Evaluating spv_mia:  21%|██▏       | 640/3000 [03:29<12:54,  3.05 examples/s]Evaluating spv_mia:  23%|██▎       | 704/3000 [03:48<12:16,  3.12 examples/s]Evaluating spv_mia:  26%|██▌       | 768/3000 [04:09<12:02,  3.09 examples/s]Evaluating spv_mia:  28%|██▊       | 832/3000 [04:33<12:06,  2.98 examples/s]Evaluating spv_mia:  30%|██▉       | 896/3000 [04:53<11:34,  3.03 examples/s]Evaluating spv_mia:  32%|███▏      | 960/3000 [05:14<11:09,  3.05 examples/s]Evaluating spv_mia:  34%|███▍      | 1024/3000 [05:35<10:47,  3.05 examples/s]Evaluating spv_mia:  36%|███▋      | 1088/3000 [05:55<10:21,  3.08 examples/s]Evaluating spv_mia:  38%|███▊      | 1152/3000 [06:18<10:17,  2.99 examples/s]Evaluating spv_mia:  41%|████      | 1216/3000 [06:37<09:42,  3.06 examples/s]Evaluating spv_mia:  43%|████▎     | 1280/3000 [07:00<09:32,  3.00 examples/s]Evaluating spv_mia:  45%|████▍     | 1344/3000 [07:24<09:31,  2.90 examples/s]Evaluating spv_mia:  47%|████▋     | 1408/3000 [07:45<09:02,  2.93 examples/s]Evaluating spv_mia:  49%|████▉     | 1472/3000 [08:10<09:02,  2.82 examples/s]Evaluating spv_mia:  51%|█████     | 1536/3000 [08:35<08:57,  2.73 examples/s]Evaluating spv_mia:  53%|█████▎    | 1600/3000 [09:02<08:54,  2.62 examples/s]Evaluating spv_mia:  55%|█████▌    | 1664/3000 [09:27<08:35,  2.59 examples/s]Evaluating spv_mia:  58%|█████▊    | 1728/3000 [09:47<07:41,  2.76 examples/s]Evaluating spv_mia:  60%|█████▉    | 1792/3000 [10:08<07:08,  2.82 examples/s]Evaluating spv_mia:  62%|██████▏   | 1856/3000 [10:29<06:36,  2.89 examples/s]Evaluating spv_mia:  64%|██████▍   | 1920/3000 [10:51<06:12,  2.90 examples/s]Evaluating spv_mia:  66%|██████▌   | 1984/3000 [11:14<05:53,  2.87 examples/s]Evaluating spv_mia:  68%|██████▊   | 2048/3000 [11:34<05:20,  2.97 examples/s]Evaluating spv_mia:  70%|███████   | 2112/3000 [11:54<04:55,  3.01 examples/s]Evaluating spv_mia:  73%|███████▎  | 2176/3000 [12:15<04:32,  3.03 examples/s]Evaluating spv_mia:  75%|███████▍  | 2240/3000 [12:36<04:09,  3.04 examples/s]Evaluating spv_mia:  77%|███████▋  | 2304/3000 [12:58<03:52,  3.00 examples/s]Evaluating spv_mia:  79%|███████▉  | 2368/3000 [13:20<03:32,  2.97 examples/s]Evaluating spv_mia:  81%|████████  | 2432/3000 [13:39<03:03,  3.09 examples/s]Evaluating spv_mia:  83%|████████▎ | 2496/3000 [14:00<02:43,  3.08 examples/s]Evaluating spv_mia:  85%|████████▌ | 2560/3000 [14:23<02:28,  2.95 examples/s]Evaluating spv_mia:  87%|████████▋ | 2624/3000 [14:43<02:04,  3.03 examples/s]Evaluating spv_mia:  90%|████████▉ | 2688/3000 [15:06<01:45,  2.97 examples/s]Evaluating spv_mia:  92%|█████████▏| 2752/3000 [15:28<01:24,  2.94 examples/s]Evaluating spv_mia:  94%|█████████▍| 2816/3000 [15:51<01:03,  2.91 examples/s]Evaluating spv_mia:  96%|█████████▌| 2880/3000 [16:12<00:41,  2.92 examples/s]Evaluating spv_mia:  98%|█████████▊| 2944/3000 [16:31<00:18,  3.05 examples/s]Evaluating spv_mia: 100%|██████████| 3000/3000 [16:49<00:00,  3.06 examples/s]Evaluating spv_mia: 100%|██████████| 3000/3000 [16:49<00:00,  2.97 examples/s]
[04/17/25 00:20:03] INFO     Train avg score: -1.2579639709393184     MIA.py:144
                    INFO     Evaluating test set:                     MIA.py:155
Evaluating spv_mia:   0%|          | 0/2000 [00:00<?, ? examples/s]Evaluating spv_mia:   3%|▎         | 64/2000 [00:20<10:11,  3.17 examples/s]Evaluating spv_mia:   6%|▋         | 128/2000 [00:42<10:25,  2.99 examples/s]Evaluating spv_mia:  10%|▉         | 192/2000 [01:06<10:33,  2.86 examples/s]Evaluating spv_mia:  13%|█▎        | 256/2000 [01:25<09:35,  3.03 examples/s]Evaluating spv_mia:  16%|█▌        | 320/2000 [01:47<09:26,  2.97 examples/s]Evaluating spv_mia:  19%|█▉        | 384/2000 [02:11<09:21,  2.88 examples/s]Evaluating spv_mia:  22%|██▏       | 448/2000 [02:33<08:59,  2.88 examples/s]Evaluating spv_mia:  26%|██▌       | 512/2000 [03:00<09:12,  2.69 examples/s]Evaluating spv_mia:  29%|██▉       | 576/2000 [03:26<09:04,  2.62 examples/s]Evaluating spv_mia:  32%|███▏      | 640/2000 [03:53<08:57,  2.53 examples/s]Evaluating spv_mia:  35%|███▌      | 704/2000 [04:17<08:26,  2.56 examples/s]Evaluating spv_mia:  38%|███▊      | 768/2000 [04:39<07:40,  2.68 examples/s]Evaluating spv_mia:  42%|████▏     | 832/2000 [05:01<07:09,  2.72 examples/s]Evaluating spv_mia:  45%|████▍     | 896/2000 [05:23<06:36,  2.78 examples/s]Evaluating spv_mia:  48%|████▊     | 960/2000 [05:44<06:03,  2.86 examples/s]Evaluating spv_mia:  51%|█████     | 1024/2000 [06:05<05:33,  2.93 examples/s]Evaluating spv_mia:  54%|█████▍    | 1088/2000 [06:27<05:11,  2.92 examples/s]Evaluating spv_mia:  58%|█████▊    | 1152/2000 [06:50<04:55,  2.87 examples/s]Evaluating spv_mia:  61%|██████    | 1216/2000 [07:11<04:29,  2.90 examples/s]Evaluating spv_mia:  64%|██████▍   | 1280/2000 [07:33<04:06,  2.92 examples/s]Evaluating spv_mia:  67%|██████▋   | 1344/2000 [07:53<03:39,  2.98 examples/s]Evaluating spv_mia:  70%|███████   | 1408/2000 [08:15<03:18,  2.98 examples/s]Evaluating spv_mia:  74%|███████▎  | 1472/2000 [08:37<02:59,  2.94 examples/s]Evaluating spv_mia:  77%|███████▋  | 1536/2000 [08:58<02:34,  3.00 examples/s]Evaluating spv_mia:  80%|████████  | 1600/2000 [09:20<02:14,  2.98 examples/s]Evaluating spv_mia:  83%|████████▎ | 1664/2000 [09:42<01:54,  2.95 examples/s]Evaluating spv_mia:  86%|████████▋ | 1728/2000 [10:01<01:28,  3.06 examples/s]Evaluating spv_mia:  90%|████████▉ | 1792/2000 [10:21<01:06,  3.11 examples/s]Evaluating spv_mia:  93%|█████████▎| 1856/2000 [10:42<00:46,  3.09 examples/s]Evaluating spv_mia:  96%|█████████▌| 1920/2000 [11:03<00:26,  3.04 examples/s]Evaluating spv_mia:  99%|█████████▉| 1984/2000 [11:25<00:05,  3.03 examples/s]Evaluating spv_mia: 100%|██████████| 2000/2000 [11:34<00:00,  2.85 examples/s]Evaluating spv_mia: 100%|██████████| 2000/2000 [11:34<00:00,  2.88 examples/s]
[04/17/25 00:31:53] INFO     Test avg score: -0.4366660036742687      MIA.py:160
Saving the dataset (0/1 shards):   0%|          | 0/3000 [00:00<?, ? examples/s]Saving the dataset (1/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 40959.20 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 39413.11 examples/s]
Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]Saving the dataset (1/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 32398.08 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 31153.96 examples/s]
[04/17/25 00:31:54] INFO     Neighbor data saved to                   MIA.py:279
                             ./data/neighbor_data/Qwen2TokenizerFast/           
                             ag_news/bs64/spv_mia                               
[04/17/25 00:31:57] INFO     =========ENDING==========                 run.py:41
                    INFO                                             0 run.py:42
                             block_size                             64          
                             metric                            spv_mia          
                             train_score                     -1.257964          
                             test_score                      -0.436666          
                             acc                                  0.81          
                             auc                              0.986363          
                             TPR@0.1%FPR(0.00100)             0.003667          
                             TPR@0.5%FPR(0.00500)             0.200667          
                             TPR@1.0%FPR(0.01000)             0.612667          
                             TPR@5.0%FPR(0.05050)                0.968          
                             FPR@99.0%TPR(0.99000)              0.0915          
                             FPR@95.0%TPR(0.94967)               0.036          
                             n_perturbed                            20          
                             n_neighbor                             25          
                             mask_ratio                            0.2          
                             refer_model              Qwen2ForCausalLM          
                             mask_model             RobertaForCausalLM          
                    INFO     Total time: 1757.4 seconds                run.py:45
Start running the experiment.
>>>> [CUDA]Cuda visible devices: 7
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `1`
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
[04/17/25 00:32:42] INFO     Loading model in int8: False   finetuned_llms.py:95
                             or half: True                                      
[04/17/25 00:32:43] INFO     > Loading the provided        finetuned_llms.py:113
                             ./ft_llms/Qwen/Qwen2.5-0.5B/a                      
                             g_news/bs64/target_base/check                      
                             point-276 checkpoint from                          
                             './ft_llms/Qwen/Qwen2.5-0.5B/                      
                             ag_news/bs64/target_base/chec                      
                             kpoint-276'.                                       
[04/17/25 00:32:59] INFO     Train dataset columns: ['text',     provider.py:149
                             'label'], select text column: text                 
[04/17/25 00:33:00] INFO     Block size: 64, max buffer size:    provider.py:162
                             235929.6                                           
[04/17/25 00:33:00] INFO     Using split dataset.                  factory.py:35
Computing length of the text(train):   0%|          | 0/3000 [00:00<?, ? examples/s]Computing length of the text(train):  61%|██████    | 1816/3000 [00:00<00:00, 17963.39 examples/s]Computing length of the text(train): 100%|██████████| 3000/3000 [00:00<00:00, 15227.21 examples/s]
Computing length of the text(test):   0%|          | 0/2000 [00:00<?, ? examples/s]Computing length of the text(test):  94%|█████████▍| 1888/2000 [00:00<00:00, 18763.44 examples/s]Computing length of the text(test): 100%|██████████| 2000/2000 [00:00<00:00, 14371.31 examples/s]
[04/17/25 00:33:00] INFO     Average Length of the string in           run.py:20
                             dataset:(285.97833333333335, 283.5965)             
                    INFO     Data preview: {'text': ' Hamadeh was      run.py:21
                             wounded Friday when his car was targeted           
                             by a remote-controlled bomb near his               
                             home. He suffered only minor injuries,             
                             but his driver was killed and a bodyguard          
                             was seriously hurt.PeopleSoft Ousts CEO            
                             Who Battled Oracle  In NEW YORK story              
                             headlined "PeopleSoft ousts CEO amid '}            
                             {'text': " anger A computer firm is                
                             criticised by the Kennedy family for               
                             producing a game recreating the                    
                             president's death.PeopleSoft Won #39;t Go          
                             Quietly A major battle is over, but the            
                             war for PeopleSoft (PSFT:Nasdaq - news -           
                             research) rages on. Executives of the              
                             business"}                                         
                    INFO     Loading model in int8: False   finetuned_llms.py:95
                             or half: True                                      
[04/17/25 00:33:01] INFO     > Loading the provided        finetuned_llms.py:113
                             ./ft_llms/Qwen/Qwen2.5-0.5B/a                      
                             g_news/bs64/self_prompt/check                      
                             point-28 checkpoint from                           
                             './ft_llms/Qwen/Qwen2.5-0.5B/                      
                             ag_news/bs64/self_prompt/chec                      
                             kpoint-28'.                                        
If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`
[04/17/25 00:33:04] INFO     Evaluating train set:                    MIA.py:140
Evaluating spv_mia:   0%|          | 0/3000 [00:00<?, ? examples/s]Evaluating spv_mia:   2%|▏         | 64/3000 [00:38<29:47,  1.64 examples/s]Evaluating spv_mia:   4%|▍         | 128/3000 [01:24<32:09,  1.49 examples/s]Evaluating spv_mia:   6%|▋         | 192/3000 [02:07<31:23,  1.49 examples/s]Evaluating spv_mia:   9%|▊         | 256/3000 [02:42<28:30,  1.60 examples/s]Evaluating spv_mia:  11%|█         | 320/3000 [03:21<27:37,  1.62 examples/s]Evaluating spv_mia:  13%|█▎        | 384/3000 [04:01<26:51,  1.62 examples/s]Evaluating spv_mia:  15%|█▍        | 448/3000 [04:36<25:16,  1.68 examples/s]Evaluating spv_mia:  17%|█▋        | 512/3000 [05:11<24:05,  1.72 examples/s]Evaluating spv_mia:  19%|█▉        | 576/3000 [05:52<24:07,  1.67 examples/s]Evaluating spv_mia:  21%|██▏       | 640/3000 [06:27<23:00,  1.71 examples/s]Evaluating spv_mia:  23%|██▎       | 704/3000 [07:03<22:04,  1.73 examples/s]Evaluating spv_mia:  26%|██▌       | 768/3000 [07:43<22:02,  1.69 examples/s]Evaluating spv_mia:  28%|██▊       | 832/3000 [08:23<21:48,  1.66 examples/s]Evaluating spv_mia:  30%|██▉       | 896/3000 [08:59<20:40,  1.70 examples/s]Evaluating spv_mia:  32%|███▏      | 960/3000 [09:35<19:42,  1.73 examples/s]Evaluating spv_mia:  34%|███▍      | 1024/3000 [10:10<18:48,  1.75 examples/s]Evaluating spv_mia:  36%|███▋      | 1088/3000 [10:45<17:59,  1.77 examples/s]Evaluating spv_mia:  38%|███▊      | 1152/3000 [11:25<17:52,  1.72 examples/s]Evaluating spv_mia:  41%|████      | 1216/3000 [11:59<16:53,  1.76 examples/s]Evaluating spv_mia:  43%|████▎     | 1280/3000 [12:39<16:43,  1.71 examples/s]Evaluating spv_mia:  45%|████▍     | 1344/3000 [13:18<16:23,  1.68 examples/s]Evaluating spv_mia:  47%|████▋     | 1408/3000 [13:58<15:57,  1.66 examples/s]Evaluating spv_mia:  49%|████▉     | 1472/3000 [14:34<14:59,  1.70 examples/s]Evaluating spv_mia:  51%|█████     | 1536/3000 [15:10<14:08,  1.73 examples/s]Evaluating spv_mia:  53%|█████▎    | 1600/3000 [15:49<13:48,  1.69 examples/s]Evaluating spv_mia:  55%|█████▌    | 1664/3000 [16:25<12:56,  1.72 examples/s]Evaluating spv_mia:  58%|█████▊    | 1728/3000 [17:00<12:07,  1.75 examples/s]Evaluating spv_mia:  60%|█████▉    | 1792/3000 [17:40<11:47,  1.71 examples/s]Evaluating spv_mia:  62%|██████▏   | 1856/3000 [18:15<11:00,  1.73 examples/s]Evaluating spv_mia:  64%|██████▍   | 1920/3000 [18:55<10:37,  1.69 examples/s]Evaluating spv_mia:  66%|██████▌   | 1984/3000 [19:35<10:08,  1.67 examples/s]Evaluating spv_mia:  68%|██████▊   | 2048/3000 [20:10<09:18,  1.71 examples/s]Evaluating spv_mia:  70%|███████   | 2112/3000 [20:46<08:33,  1.73 examples/s]Evaluating spv_mia:  73%|███████▎  | 2176/3000 [21:22<07:51,  1.75 examples/s]Evaluating spv_mia:  75%|███████▍  | 2240/3000 [22:01<07:25,  1.71 examples/s]Evaluating spv_mia:  77%|███████▋  | 2304/3000 [22:42<06:57,  1.67 examples/s]Evaluating spv_mia:  79%|███████▉  | 2368/3000 [23:17<06:09,  1.71 examples/s]Evaluating spv_mia:  81%|████████  | 2432/3000 [23:52<05:25,  1.74 examples/s]Evaluating spv_mia:  83%|████████▎ | 2496/3000 [24:27<04:45,  1.76 examples/s]Evaluating spv_mia:  85%|████████▌ | 2560/3000 [25:07<04:17,  1.71 examples/s]Evaluating spv_mia:  87%|████████▋ | 2624/3000 [25:43<03:36,  1.74 examples/s]Evaluating spv_mia:  90%|████████▉ | 2688/3000 [26:23<03:05,  1.69 examples/s]Evaluating spv_mia:  92%|█████████▏| 2752/3000 [27:03<02:29,  1.66 examples/s]Evaluating spv_mia:  94%|█████████▍| 2816/3000 [27:44<01:52,  1.63 examples/s]Evaluating spv_mia:  96%|█████████▌| 2880/3000 [28:20<01:11,  1.68 examples/s]Evaluating spv_mia:  98%|█████████▊| 2944/3000 [28:54<00:32,  1.72 examples/s]Evaluating spv_mia: 100%|██████████| 3000/3000 [29:26<00:00,  1.74 examples/s]Evaluating spv_mia: 100%|██████████| 3000/3000 [29:26<00:00,  1.70 examples/s]
[04/17/25 01:02:46] INFO     Train avg score: -1.2663854212363561     MIA.py:144
                    INFO     Evaluating test set:                     MIA.py:155
Evaluating spv_mia:   0%|          | 0/2000 [00:00<?, ? examples/s]Evaluating spv_mia:   3%|▎         | 64/2000 [00:35<17:54,  1.80 examples/s]Evaluating spv_mia:   6%|▋         | 128/2000 [01:15<18:33,  1.68 examples/s]Evaluating spv_mia:  10%|▉         | 192/2000 [01:55<18:20,  1.64 examples/s]Evaluating spv_mia:  13%|█▎        | 256/2000 [02:30<17:05,  1.70 examples/s]Evaluating spv_mia:  16%|█▌        | 320/2000 [03:11<16:50,  1.66 examples/s]Evaluating spv_mia:  19%|█▉        | 384/2000 [03:50<16:18,  1.65 examples/s]Evaluating spv_mia:  22%|██▏       | 448/2000 [04:29<15:45,  1.64 examples/s]Evaluating spv_mia:  26%|██▌       | 512/2000 [05:09<15:08,  1.64 examples/s]Evaluating spv_mia:  29%|██▉       | 576/2000 [05:44<14:05,  1.68 examples/s]Evaluating spv_mia:  32%|███▏      | 640/2000 [06:24<13:38,  1.66 examples/s]Evaluating spv_mia:  35%|███▌      | 704/2000 [07:00<12:42,  1.70 examples/s]Evaluating spv_mia:  38%|███▊      | 768/2000 [07:39<12:16,  1.67 examples/s]Evaluating spv_mia:  42%|████▏     | 832/2000 [08:20<11:51,  1.64 examples/s]Evaluating spv_mia:  45%|████▍     | 896/2000 [09:00<11:19,  1.62 examples/s]Evaluating spv_mia:  48%|████▊     | 960/2000 [09:37<10:26,  1.66 examples/s]Evaluating spv_mia:  51%|█████     | 1024/2000 [10:17<09:56,  1.64 examples/s]Evaluating spv_mia:  54%|█████▍    | 1088/2000 [10:58<09:23,  1.62 examples/s]Evaluating spv_mia:  58%|█████▊    | 1152/2000 [11:38<08:47,  1.61 examples/s]Evaluating spv_mia:  61%|██████    | 1216/2000 [12:19<08:10,  1.60 examples/s]Evaluating spv_mia:  64%|██████▍   | 1280/2000 [12:59<07:31,  1.60 examples/s]Evaluating spv_mia:  67%|██████▋   | 1344/2000 [13:35<06:37,  1.65 examples/s]Evaluating spv_mia:  70%|███████   | 1408/2000 [14:15<06:03,  1.63 examples/s]Evaluating spv_mia:  74%|███████▎  | 1472/2000 [14:56<05:28,  1.61 examples/s]Evaluating spv_mia:  77%|███████▋  | 1536/2000 [15:37<04:49,  1.60 examples/s]Evaluating spv_mia:  80%|████████  | 1600/2000 [16:17<04:10,  1.60 examples/s]Evaluating spv_mia:  83%|████████▎ | 1664/2000 [16:54<03:25,  1.64 examples/s]Evaluating spv_mia:  86%|████████▋ | 1728/2000 [17:29<02:41,  1.68 examples/s]Evaluating spv_mia:  90%|████████▉ | 1792/2000 [18:05<02:01,  1.72 examples/s]Evaluating spv_mia:  93%|█████████▎| 1856/2000 [18:40<01:22,  1.74 examples/s]Evaluating spv_mia:  96%|█████████▌| 1920/2000 [19:19<00:46,  1.71 examples/s]Evaluating spv_mia:  99%|█████████▉| 1984/2000 [19:59<00:09,  1.68 examples/s]Evaluating spv_mia: 100%|██████████| 2000/2000 [20:10<00:00,  1.65 examples/s]Evaluating spv_mia: 100%|██████████| 2000/2000 [20:10<00:00,  1.65 examples/s]
[04/17/25 01:23:11] INFO     Test avg score: -0.43231673213839533     MIA.py:160
Saving the dataset (0/1 shards):   0%|          | 0/3000 [00:00<?, ? examples/s]Saving the dataset (0/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 21813.03 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 21813.03 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 19897.61 examples/s]
Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]Saving the dataset (1/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 20628.27 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 19951.07 examples/s]
[04/17/25 01:23:12] INFO     Neighbor data saved to                   MIA.py:279
                             ./data/neighbor_data/Qwen2TokenizerFast/           
                             ag_news/bs64/spv_mia                               
                    INFO     =========ENDING==========                 run.py:41
                    INFO                                             0 run.py:42
                             block_size                             64          
                             metric                            spv_mia          
                             train_score                     -1.266385          
                             test_score                      -0.432317          
                             acc                                0.8036          
                             auc                              0.983929          
                             TPR@0.1%FPR(0.00100)                0.005          
                             TPR@0.5%FPR(0.00500)                0.224          
                             TPR@1.0%FPR(0.01000)                0.569          
                             TPR@5.0%FPR(0.05050)                0.966          
                             FPR@99.0%TPR(0.98967)               0.137          
                             FPR@95.0%TPR(0.94700)              0.0385          
                             n_perturbed                            50          
                             n_neighbor                             25          
                             mask_ratio                            0.2          
                             refer_model              Qwen2ForCausalLM          
                             mask_model             RobertaForCausalLM          
                    INFO     Total time: 3030.4 seconds                run.py:45
Start running the experiment.
>>>> [CUDA]Cuda visible devices: 7
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `1`
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
[04/17/25 01:23:23] INFO     Loading model in int8: False   finetuned_llms.py:95
                             or half: True                                      
[04/17/25 01:23:24] INFO     > Loading the provided        finetuned_llms.py:113
                             ./ft_llms/Qwen/Qwen2.5-0.5B/a                      
                             g_news/bs128/target_base/chec                      
                             kpoint-465 checkpoint from                         
                             './ft_llms/Qwen/Qwen2.5-0.5B/                      
                             ag_news/bs128/target_base/che                      
                             ckpoint-465'.                                      
[04/17/25 01:23:37] INFO     Train dataset columns: ['text',     provider.py:149
                             'label'], select text column: text                 
                    INFO     Block size: 128, max buffer size:   provider.py:162
                             471859.2                                           
[04/17/25 01:23:37] INFO     Using split dataset.                  factory.py:35
Computing length of the text(train):   0%|          | 0/3000 [00:00<?, ? examples/s]Computing length of the text(train):  50%|████▉     | 1490/3000 [00:00<00:00, 14816.96 examples/s]Computing length of the text(train): 100%|██████████| 3000/3000 [00:00<00:00, 14559.61 examples/s]
Computing length of the text(test):   0%|          | 0/2000 [00:00<?, ? examples/s]Computing length of the text(test):  89%|████████▉ | 1776/2000 [00:00<00:00, 17661.06 examples/s]Computing length of the text(test): 100%|██████████| 2000/2000 [00:00<00:00, 15474.85 examples/s]
[04/17/25 01:23:37] INFO     Average Length of the string in           run.py:20
                             dataset:(575.974, 564.36)                          
                    INFO     Data preview: {'text': "\\gunships,       run.py:21
                             pounded positions held by Shi'ite                  
                             militiamen in the\\Iraqi holy city of              
                             Najaf Thursday and large orange                    
                             multiple\\flashes lit the night sky.Iraq           
                             Oil Exports Unchanged After Basra Attack           
                             (Reuters) Reuters - Iraq's oil exports             
                             are still flowing at\\one million barrels          
                             per day through southern terminals                 
                             despite\\an attack on the South Oil                
                             Company headquarters on Thursday, an\\oil          
                             official at the company said.Canada Says           
                             G7 Not Doing Enough to Help Africa                 
                             (Reuters) Reuters - Leaders from the               
                             Group of Seven rich\\industrialized                
                             nations need to do more to aid poor                
                             African\\countries"}                               
                             {'text': ".New eggs surgery prodedure              
                             brings 20 babies, and many questions               
                             After doctors performed a kind of                  
                             transplant surgery on mothers eggs, 20             
                             babies were born to women for whom IVF             
                             had not worked.EU to Rule Tuesday on               
                             Oracle's Bid for PeopleSoft European               
                             Union regulators will decide Tuesday               
                             whether Oracle Corp.'s hostile \\$7.7              
                             billion bid for rival business software            
                             concern PeopleSoft Inc. can proceed, the           
                             EU's antitrust chief said                          
                             Friday.Americans Using Online Reputation           
                             Systems A quarter of online Americans              
                             have taken advantage of one of the                 
                             Internet's true powers: the ability to             
                             let users collectively decide whether to           
                             trust a product"}                                  
                    INFO     Loading model in int8: False   finetuned_llms.py:95
                             or half: True                                      
[04/17/25 01:23:38] INFO     > Loading the provided        finetuned_llms.py:113
                             ./ft_llms/Qwen/Qwen2.5-0.5B/a                      
                             g_news/bs128/self_prompt/chec                      
                             kpoint-168 checkpoint from                         
                             './ft_llms/Qwen/Qwen2.5-0.5B/                      
                             ag_news/bs128/self_prompt/che                      
                             ckpoint-168'.                                      
If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`
[04/17/25 01:23:41] INFO     Evaluating train set:                    MIA.py:140
Evaluating spv_mia:   0%|          | 0/3000 [00:00<?, ? examples/s]Evaluating spv_mia:   2%|▏         | 64/3000 [00:39<30:34,  1.60 examples/s]Evaluating spv_mia:   4%|▍         | 128/3000 [01:23<31:19,  1.53 examples/s]Evaluating spv_mia:   6%|▋         | 192/3000 [02:03<30:11,  1.55 examples/s]Evaluating spv_mia:   9%|▊         | 256/3000 [02:47<30:12,  1.51 examples/s]Evaluating spv_mia:  11%|█         | 320/3000 [03:27<29:01,  1.54 examples/s]Evaluating spv_mia:  13%|█▎        | 384/3000 [04:11<28:52,  1.51 examples/s]Evaluating spv_mia:  15%|█▍        | 448/3000 [04:51<27:39,  1.54 examples/s]Evaluating spv_mia:  17%|█▋        | 512/3000 [05:35<27:26,  1.51 examples/s]Evaluating spv_mia:  19%|█▉        | 576/3000 [06:15<26:11,  1.54 examples/s]Evaluating spv_mia:  21%|██▏       | 640/3000 [06:59<26:00,  1.51 examples/s]Evaluating spv_mia:  23%|██▎       | 704/3000 [07:43<25:33,  1.50 examples/s]Evaluating spv_mia:  26%|██▌       | 768/3000 [08:22<24:16,  1.53 examples/s]Evaluating spv_mia:  28%|██▊       | 832/3000 [09:06<23:50,  1.52 examples/s]Evaluating spv_mia:  30%|██▉       | 896/3000 [09:45<22:43,  1.54 examples/s]Evaluating spv_mia:  32%|███▏      | 960/3000 [10:29<22:22,  1.52 examples/s]Evaluating spv_mia:  34%|███▍      | 1024/3000 [11:12<21:48,  1.51 examples/s]Evaluating spv_mia:  36%|███▋      | 1088/3000 [11:52<20:44,  1.54 examples/s]Evaluating spv_mia:  38%|███▊      | 1152/3000 [12:32<19:47,  1.56 examples/s]Evaluating spv_mia:  41%|████      | 1216/3000 [13:12<18:56,  1.57 examples/s]Evaluating spv_mia:  43%|████▎     | 1280/3000 [13:55<18:37,  1.54 examples/s]Evaluating spv_mia:  45%|████▍     | 1344/3000 [14:39<18:11,  1.52 examples/s]Evaluating spv_mia:  47%|████▋     | 1408/3000 [15:19<17:11,  1.54 examples/s]Evaluating spv_mia:  49%|████▉     | 1472/3000 [16:02<16:46,  1.52 examples/s]Evaluating spv_mia:  51%|█████     | 1536/3000 [16:45<16:09,  1.51 examples/s]Evaluating spv_mia:  53%|█████▎    | 1600/3000 [17:25<15:07,  1.54 examples/s]Evaluating spv_mia:  55%|█████▌    | 1664/3000 [18:05<14:20,  1.55 examples/s]Evaluating spv_mia:  58%|█████▊    | 1728/3000 [18:45<13:28,  1.57 examples/s]Evaluating spv_mia:  60%|█████▉    | 1792/3000 [19:28<13:01,  1.55 examples/s]Evaluating spv_mia:  62%|██████▏   | 1856/3000 [20:08<12:12,  1.56 examples/s]Evaluating spv_mia:  64%|██████▍   | 1920/3000 [20:52<11:47,  1.53 examples/s]Evaluating spv_mia:  66%|██████▌   | 1984/3000 [21:32<10:55,  1.55 examples/s]Evaluating spv_mia:  68%|██████▊   | 2048/3000 [22:12<10:08,  1.57 examples/s]Evaluating spv_mia:  70%|███████   | 2112/3000 [22:55<09:37,  1.54 examples/s]Evaluating spv_mia:  73%|███████▎  | 2176/3000 [23:42<09:15,  1.48 examples/s]Evaluating spv_mia:  75%|███████▍  | 2240/3000 [24:25<08:31,  1.48 examples/s]Evaluating spv_mia:  77%|███████▋  | 2304/3000 [25:08<07:49,  1.48 examples/s]Evaluating spv_mia:  79%|███████▉  | 2368/3000 [25:48<06:57,  1.51 examples/s]Evaluating spv_mia:  81%|████████  | 2432/3000 [26:32<06:20,  1.49 examples/s]Evaluating spv_mia:  83%|████████▎ | 2496/3000 [27:12<05:30,  1.52 examples/s]Evaluating spv_mia:  85%|████████▌ | 2560/3000 [27:55<04:50,  1.52 examples/s]Evaluating spv_mia:  87%|████████▋ | 2624/3000 [28:35<04:03,  1.55 examples/s]Evaluating spv_mia:  90%|████████▉ | 2688/3000 [29:15<03:20,  1.56 examples/s]Evaluating spv_mia:  92%|█████████▏| 2752/3000 [29:55<02:38,  1.56 examples/s]Evaluating spv_mia:  94%|█████████▍| 2816/3000 [30:43<02:03,  1.49 examples/s]Evaluating spv_mia:  96%|█████████▌| 2880/3000 [31:35<01:25,  1.41 examples/s]Evaluating spv_mia:  98%|█████████▊| 2944/3000 [32:22<00:40,  1.39 examples/s]Evaluating spv_mia: 100%|██████████| 3000/3000 [33:06<00:00,  1.35 examples/s]Evaluating spv_mia: 100%|██████████| 3000/3000 [33:06<00:00,  1.51 examples/s]
[04/17/25 01:57:02] INFO     Train avg score: -0.8567496996223927     MIA.py:144
                    INFO     Evaluating test set:                     MIA.py:155
Evaluating spv_mia:   0%|          | 0/2000 [00:00<?, ? examples/s]Evaluating spv_mia:   3%|▎         | 64/2000 [00:50<25:22,  1.27 examples/s]Evaluating spv_mia:   6%|▋         | 128/2000 [01:37<23:36,  1.32 examples/s]Evaluating spv_mia:  10%|▉         | 192/2000 [02:27<23:10,  1.30 examples/s]Evaluating spv_mia:  13%|█▎        | 256/2000 [03:14<21:53,  1.33 examples/s]Evaluating spv_mia:  16%|█▌        | 320/2000 [04:03<21:18,  1.31 examples/s]Evaluating spv_mia:  19%|█▉        | 384/2000 [04:50<20:13,  1.33 examples/s]Evaluating spv_mia:  22%|██▏       | 448/2000 [05:40<19:35,  1.32 examples/s]Evaluating spv_mia:  26%|██▌       | 512/2000 [06:32<19:18,  1.28 examples/s]Evaluating spv_mia:  29%|██▉       | 576/2000 [07:17<17:56,  1.32 examples/s]Evaluating spv_mia:  32%|███▏      | 640/2000 [08:01<16:35,  1.37 examples/s]Evaluating spv_mia:  35%|███▌      | 704/2000 [08:48<15:50,  1.36 examples/s]Evaluating spv_mia:  38%|███▊      | 768/2000 [09:37<15:15,  1.35 examples/s]Evaluating spv_mia:  42%|████▏     | 832/2000 [10:22<14:13,  1.37 examples/s]Evaluating spv_mia:  45%|████▍     | 896/2000 [11:07<13:19,  1.38 examples/s]Evaluating spv_mia:  48%|████▊     | 960/2000 [12:00<13:04,  1.33 examples/s]Evaluating spv_mia:  51%|█████     | 1024/2000 [12:49<12:18,  1.32 examples/s]Evaluating spv_mia:  54%|█████▍    | 1088/2000 [13:37<11:28,  1.33 examples/s]Evaluating spv_mia:  58%|█████▊    | 1152/2000 [14:26<10:42,  1.32 examples/s]Evaluating spv_mia:  61%|██████    | 1216/2000 [15:15<09:55,  1.32 examples/s]Evaluating spv_mia:  64%|██████▍   | 1280/2000 [16:04<09:10,  1.31 examples/s]Evaluating spv_mia:  67%|██████▋   | 1344/2000 [16:49<08:09,  1.34 examples/s]Evaluating spv_mia:  70%|███████   | 1408/2000 [17:33<07:11,  1.37 examples/s]Evaluating spv_mia:  74%|███████▎  | 1472/2000 [18:18<06:20,  1.39 examples/s]Evaluating spv_mia:  77%|███████▋  | 1536/2000 [19:03<05:30,  1.40 examples/s]Evaluating spv_mia:  80%|████████  | 1600/2000 [19:44<04:37,  1.44 examples/s]Evaluating spv_mia:  83%|████████▎ | 1664/2000 [20:33<03:59,  1.40 examples/s]Evaluating spv_mia:  86%|████████▋ | 1728/2000 [21:17<03:12,  1.41 examples/s]Evaluating spv_mia:  90%|████████▉ | 1792/2000 [22:04<02:29,  1.40 examples/s]Evaluating spv_mia:  93%|█████████▎| 1856/2000 [22:50<01:42,  1.40 examples/s]Evaluating spv_mia:  96%|█████████▌| 1920/2000 [23:36<00:57,  1.39 examples/s]Evaluating spv_mia:  99%|█████████▉| 1984/2000 [24:20<00:11,  1.41 examples/s]Evaluating spv_mia: 100%|██████████| 2000/2000 [24:32<00:00,  1.40 examples/s]Evaluating spv_mia: 100%|██████████| 2000/2000 [24:32<00:00,  1.36 examples/s]
[04/17/25 02:21:54] INFO     Test avg score: -0.2962747517824173      MIA.py:160
Saving the dataset (0/1 shards):   0%|          | 0/3000 [00:00<?, ? examples/s]Saving the dataset (0/1 shards):  67%|██████▋   | 2000/3000 [00:00<00:00, 15414.65 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 15414.65 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 16216.53 examples/s]
Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]Saving the dataset (1/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 28710.41 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 24895.71 examples/s]
[04/17/25 02:21:55] INFO     Neighbor data saved to                   MIA.py:279
                             ./data/neighbor_data/Qwen2TokenizerFast/           
                             ag_news/bs128/spv_mia                              
                    INFO     =========ENDING==========                 run.py:41
                    INFO                                             0 run.py:42
                             block_size                            128          
                             metric                            spv_mia          
                             train_score                      -0.85675          
                             test_score                      -0.296275          
                             acc                                0.8374          
                             auc                               0.96545          
                             TPR@0.1%FPR(0.00100)                0.003          
                             TPR@0.5%FPR(0.00550)             0.009333          
                             TPR@1.0%FPR(0.01000)             0.135667          
                             TPR@5.0%FPR(0.05000)             0.826667          
                             FPR@99.0%TPR(0.99000)               0.118          
                             FPR@95.0%TPR(0.94700)               0.076          
                             n_perturbed                            20          
                             n_neighbor                             25          
                             mask_ratio                            0.2          
                             refer_model              Qwen2ForCausalLM          
                             mask_model             RobertaForCausalLM          
                    INFO     Total time: 3511.3 seconds                run.py:45
Start running the experiment.
>>>> [CUDA]Cuda visible devices: 7
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `1`
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
[04/17/25 02:22:10] INFO     Loading model in int8: False   finetuned_llms.py:95
                             or half: True                                      
[04/17/25 02:22:11] INFO     > Loading the provided        finetuned_llms.py:113
                             ./ft_llms/Qwen/Qwen2.5-0.5B/a                      
                             g_news/bs128/target_base/chec                      
                             kpoint-465 checkpoint from                         
                             './ft_llms/Qwen/Qwen2.5-0.5B/                      
                             ag_news/bs128/target_base/che                      
                             ckpoint-465'.                                      
[04/17/25 02:24:27] INFO     Train dataset columns: ['text',     provider.py:149
                             'label'], select text column: text                 
                    INFO     Block size: 128, max buffer size:   provider.py:162
                             471859.2                                           
[04/17/25 02:24:27] INFO     Using split dataset.                  factory.py:35
Computing length of the text(train):   0%|          | 0/3000 [00:00<?, ? examples/s]Computing length of the text(train):  48%|████▊     | 1449/3000 [00:00<00:00, 14411.26 examples/s]Computing length of the text(train): 100%|██████████| 3000/3000 [00:00<00:00, 11536.04 examples/s]Computing length of the text(train): 100%|██████████| 3000/3000 [00:00<00:00, 11337.19 examples/s]
Computing length of the text(test):   0%|          | 0/2000 [00:00<?, ? examples/s]Computing length of the text(test):  54%|█████▎    | 1070/2000 [00:00<00:00, 10601.21 examples/s]Computing length of the text(test): 100%|██████████| 2000/2000 [00:00<00:00, 9876.61 examples/s] 
[04/17/25 02:24:27] INFO     Average Length of the string in           run.py:20
                             dataset:(575.974, 564.36)                          
[04/17/25 02:24:28] INFO     Data preview: {'text': "\\gunships,       run.py:21
                             pounded positions held by Shi'ite                  
                             militiamen in the\\Iraqi holy city of              
                             Najaf Thursday and large orange                    
                             multiple\\flashes lit the night sky.Iraq           
                             Oil Exports Unchanged After Basra Attack           
                             (Reuters) Reuters - Iraq's oil exports             
                             are still flowing at\\one million barrels          
                             per day through southern terminals                 
                             despite\\an attack on the South Oil                
                             Company headquarters on Thursday, an\\oil          
                             official at the company said.Canada Says           
                             G7 Not Doing Enough to Help Africa                 
                             (Reuters) Reuters - Leaders from the               
                             Group of Seven rich\\industrialized                
                             nations need to do more to aid poor                
                             African\\countries"}                               
                             {'text': ".New eggs surgery prodedure              
                             brings 20 babies, and many questions               
                             After doctors performed a kind of                  
                             transplant surgery on mothers eggs, 20             
                             babies were born to women for whom IVF             
                             had not worked.EU to Rule Tuesday on               
                             Oracle's Bid for PeopleSoft European               
                             Union regulators will decide Tuesday               
                             whether Oracle Corp.'s hostile \\$7.7              
                             billion bid for rival business software            
                             concern PeopleSoft Inc. can proceed, the           
                             EU's antitrust chief said                          
                             Friday.Americans Using Online Reputation           
                             Systems A quarter of online Americans              
                             have taken advantage of one of the                 
                             Internet's true powers: the ability to             
                             let users collectively decide whether to           
                             trust a product"}                                  
                    INFO     Loading model in int8: False   finetuned_llms.py:95
                             or half: True                                      
                    INFO     > Loading the provided        finetuned_llms.py:113
                             ./ft_llms/Qwen/Qwen2.5-0.5B/a                      
                             g_news/bs128/self_prompt/chec                      
                             kpoint-168 checkpoint from                         
                             './ft_llms/Qwen/Qwen2.5-0.5B/                      
                             ag_news/bs128/self_prompt/che                      
                             ckpoint-168'.                                      
If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`
[04/17/25 02:24:32] INFO     Evaluating train set:                    MIA.py:140
Evaluating spv_mia:   0%|          | 0/3000 [00:00<?, ? examples/s]Evaluating spv_mia:   2%|▏         | 64/3000 [01:36<1:13:37,  1.50s/ examples]Evaluating spv_mia:   4%|▍         | 128/3000 [03:21<1:15:47,  1.58s/ examples]Evaluating spv_mia:   6%|▋         | 192/3000 [04:59<1:13:00,  1.56s/ examples]Evaluating spv_mia:   9%|▊         | 256/3000 [06:45<1:13:01,  1.60s/ examples]Evaluating spv_mia:  11%|█         | 320/3000 [08:22<1:10:10,  1.57s/ examples]Evaluating spv_mia:  13%|█▎        | 384/3000 [10:13<1:10:55,  1.63s/ examples]Evaluating spv_mia:  15%|█▍        | 448/3000 [11:52<1:08:08,  1.60s/ examples]Evaluating spv_mia:  17%|█▋        | 512/3000 [13:38<1:07:05,  1.62s/ examples]Evaluating spv_mia:  19%|█▉        | 576/3000 [15:14<1:03:46,  1.58s/ examples]Evaluating spv_mia:  21%|██▏       | 640/3000 [17:00<1:03:10,  1.61s/ examples]Evaluating spv_mia:  23%|██▎       | 704/3000 [18:46<1:01:57,  1.62s/ examples]Evaluating spv_mia:  26%|██▌       | 768/3000 [20:21<58:40,  1.58s/ examples]  Evaluating spv_mia:  28%|██▊       | 832/3000 [22:13<58:54,  1.63s/ examples]Evaluating spv_mia:  30%|██▉       | 896/3000 [23:48<55:42,  1.59s/ examples]Evaluating spv_mia:  32%|███▏      | 960/3000 [25:34<54:40,  1.61s/ examples]Evaluating spv_mia:  34%|███▍      | 1024/3000 [27:18<53:02,  1.61s/ examples]Evaluating spv_mia:  36%|███▋      | 1088/3000 [28:54<50:23,  1.58s/ examples]Evaluating spv_mia:  38%|███▊      | 1152/3000 [30:31<48:05,  1.56s/ examples]Evaluating spv_mia:  41%|████      | 1216/3000 [32:10<46:15,  1.56s/ examples]Evaluating spv_mia:  43%|████▎     | 1280/3000 [34:00<45:58,  1.60s/ examples]Evaluating spv_mia:  45%|████▍     | 1344/3000 [35:46<44:39,  1.62s/ examples]Evaluating spv_mia:  47%|████▋     | 1408/3000 [37:21<41:57,  1.58s/ examples]Evaluating spv_mia:  49%|████▉     | 1472/3000 [39:08<40:54,  1.61s/ examples]Evaluating spv_mia:  51%|█████     | 1536/3000 [40:53<39:24,  1.61s/ examples]Evaluating spv_mia:  53%|█████▎    | 1600/3000 [42:27<36:44,  1.57s/ examples]Evaluating spv_mia:  55%|█████▌    | 1664/3000 [44:10<35:17,  1.58s/ examples]Evaluating spv_mia:  58%|█████▊    | 1728/3000 [45:47<33:07,  1.56s/ examples]Evaluating spv_mia:  60%|█████▉    | 1792/3000 [47:30<31:45,  1.58s/ examples]Evaluating spv_mia:  62%|██████▏   | 1856/3000 [49:05<29:33,  1.55s/ examples]Evaluating spv_mia:  64%|██████▍   | 1920/3000 [50:51<28:29,  1.58s/ examples]Evaluating spv_mia:  66%|██████▌   | 1984/3000 [52:27<26:21,  1.56s/ examples]Evaluating spv_mia:  68%|██████▊   | 2048/3000 [54:01<24:17,  1.53s/ examples]Evaluating spv_mia:  70%|███████   | 2112/3000 [55:51<23:29,  1.59s/ examples]Evaluating spv_mia:  73%|███████▎  | 2176/3000 [57:47<22:41,  1.65s/ examples]Evaluating spv_mia:  75%|███████▍  | 2240/3000 [59:29<20:44,  1.64s/ examples]Evaluating spv_mia:  77%|███████▋  | 2304/3000 [1:01:14<18:58,  1.64s/ examples]Evaluating spv_mia:  79%|███████▉  | 2368/3000 [1:02:50<16:49,  1.60s/ examples]Evaluating spv_mia:  81%|████████  | 2432/3000 [1:04:36<15:17,  1.62s/ examples]Evaluating spv_mia:  83%|████████▎ | 2496/3000 [1:06:14<13:20,  1.59s/ examples]Evaluating spv_mia:  85%|████████▌ | 2560/3000 [1:08:02<11:52,  1.62s/ examples]Evaluating spv_mia:  87%|████████▋ | 2624/3000 [1:09:37<09:53,  1.58s/ examples]Evaluating spv_mia:  90%|████████▉ | 2688/3000 [1:11:14<08:06,  1.56s/ examples]Evaluating spv_mia:  92%|█████████▏| 2752/3000 [1:12:50<06:22,  1.54s/ examples]Evaluating spv_mia:  94%|█████████▍| 2816/3000 [1:14:36<04:49,  1.58s/ examples]Evaluating spv_mia:  96%|█████████▌| 2880/3000 [1:16:22<03:11,  1.60s/ examples]Evaluating spv_mia:  98%|█████████▊| 2944/3000 [1:18:01<01:28,  1.59s/ examples]Evaluating spv_mia: 100%|██████████| 3000/3000 [1:19:36<00:00,  1.62s/ examples]Evaluating spv_mia: 100%|██████████| 3000/3000 [1:19:37<00:00,  1.59s/ examples]
[04/17/25 03:44:25] INFO     Train avg score: -0.8921208520233631     MIA.py:144
                    INFO     Evaluating test set:                     MIA.py:155
Evaluating spv_mia:   0%|          | 0/2000 [00:00<?, ? examples/s]Evaluating spv_mia:   3%|▎         | 64/2000 [01:43<52:17,  1.62s/ examples]Evaluating spv_mia:   6%|▋         | 128/2000 [03:18<48:05,  1.54s/ examples]Evaluating spv_mia:  10%|▉         | 192/2000 [05:04<47:52,  1.59s/ examples]Evaluating spv_mia:  13%|█▎        | 256/2000 [06:39<44:59,  1.55s/ examples]Evaluating spv_mia:  16%|█▌        | 320/2000 [08:23<44:08,  1.58s/ examples]Evaluating spv_mia:  19%|█▉        | 384/2000 [10:02<42:15,  1.57s/ examples]Evaluating spv_mia:  22%|██▏       | 448/2000 [11:50<41:29,  1.60s/ examples]Evaluating spv_mia:  26%|██▌       | 512/2000 [13:43<41:04,  1.66s/ examples]Evaluating spv_mia:  29%|██▉       | 576/2000 [15:18<38:04,  1.60s/ examples]Evaluating spv_mia:  32%|███▏      | 640/2000 [16:53<35:33,  1.57s/ examples]Evaluating spv_mia:  35%|███▌      | 704/2000 [18:36<34:07,  1.58s/ examples]Evaluating spv_mia:  38%|███▊      | 768/2000 [20:19<32:37,  1.59s/ examples]Evaluating spv_mia:  42%|████▏     | 832/2000 [22:00<30:51,  1.59s/ examples]Evaluating spv_mia:  45%|████▍     | 896/2000 [23:36<28:40,  1.56s/ examples]Evaluating spv_mia:  48%|████▊     | 960/2000 [25:30<28:12,  1.63s/ examples]Evaluating spv_mia:  51%|█████     | 1024/2000 [27:14<26:28,  1.63s/ examples]Evaluating spv_mia:  54%|█████▍    | 1088/2000 [28:57<24:36,  1.62s/ examples]Evaluating spv_mia:  58%|█████▊    | 1152/2000 [30:41<22:53,  1.62s/ examples]Evaluating spv_mia:  61%|██████    | 1216/2000 [32:27<21:19,  1.63s/ examples]Evaluating spv_mia:  64%|██████▍   | 1280/2000 [34:21<20:08,  1.68s/ examples]Evaluating spv_mia:  67%|██████▋   | 1344/2000 [36:05<18:10,  1.66s/ examples]Evaluating spv_mia:  70%|███████   | 1408/2000 [37:50<16:18,  1.65s/ examples]Evaluating spv_mia:  74%|███████▎  | 1472/2000 [39:32<14:23,  1.64s/ examples]Evaluating spv_mia:  77%|███████▋  | 1536/2000 [41:16<12:38,  1.63s/ examples]Evaluating spv_mia:  80%|████████  | 1600/2000 [42:51<10:36,  1.59s/ examples]Evaluating spv_mia:  83%|████████▎ | 1664/2000 [44:49<09:18,  1.66s/ examples]Evaluating spv_mia:  86%|████████▋ | 1728/2000 [46:31<07:27,  1.65s/ examples]Evaluating spv_mia:  90%|████████▉ | 1792/2000 [48:17<05:42,  1.65s/ examples]Evaluating spv_mia:  93%|█████████▎| 1856/2000 [50:01<03:56,  1.64s/ examples]Evaluating spv_mia:  96%|█████████▌| 1920/2000 [51:44<02:10,  1.63s/ examples]Evaluating spv_mia:  99%|█████████▉| 1984/2000 [53:26<00:25,  1.62s/ examples]Evaluating spv_mia: 100%|██████████| 2000/2000 [53:53<00:00,  1.63s/ examples]Evaluating spv_mia: 100%|██████████| 2000/2000 [53:53<00:00,  1.62s/ examples]
[04/17/25 04:38:34] INFO     Test avg score: -0.3230127002000809      MIA.py:160
Saving the dataset (0/1 shards):   0%|          | 0/3000 [00:00<?, ? examples/s]Saving the dataset (0/1 shards):  67%|██████▋   | 2000/3000 [00:00<00:00, 13407.59 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 13407.59 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 13370.97 examples/s]
Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]Saving the dataset (0/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 15648.64 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 15648.64 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 14725.41 examples/s]
[04/17/25 04:38:36] INFO     Neighbor data saved to                   MIA.py:279
                             ./data/neighbor_data/Qwen2TokenizerFast/           
                             ag_news/bs128/spv_mia                              
                    INFO     =========ENDING==========                 run.py:41
                    INFO                                             0 run.py:42
                             block_size                            128          
                             metric                            spv_mia          
                             train_score                     -0.892121          
                             test_score                      -0.323013          
                             acc                                 0.838          
                             auc                               0.96021          
                             TPR@0.1%FPR(0.00100)             0.004333          
                             TPR@0.5%FPR(0.00550)             0.009333          
                             TPR@1.0%FPR(0.01000)             0.093667          
                             TPR@5.0%FPR(0.05050)             0.694667          
                             FPR@99.0%TPR(0.98933)               0.122          
                             FPR@95.0%TPR(0.94967)              0.0905          
                             n_perturbed                            50          
                             n_neighbor                             25          
                             mask_ratio                            0.2          
                             refer_model              Qwen2ForCausalLM          
                             mask_model             RobertaForCausalLM          
                    INFO     Total time: 8186.0 seconds                run.py:45
Start running the experiment.
>>>> [CUDA]Cuda visible devices: 7
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `1`
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
[04/17/25 04:38:50] INFO     Loading model in int8: False   finetuned_llms.py:95
                             or half: True                                      
[04/17/25 04:38:51] INFO     > Loading the provided        finetuned_llms.py:113
                             ./ft_llms/Qwen/Qwen2.5-1.5B/a                      
                             g_news/bs32/target_base/check                      
                             point-230 checkpoint from                          
                             './ft_llms/Qwen/Qwen2.5-1.5B/                      
                             ag_news/bs32/target_base/chec                      
                             kpoint-230'.                                       
[04/17/25 04:40:54] INFO     Train dataset columns: ['text',     provider.py:149
                             'label'], select text column: text                 
                    INFO     Block size: 32, max buffer size:    provider.py:162
                             117964.8                                           
[04/17/25 04:40:55] INFO     Using split dataset.                  factory.py:35
Computing length of the text(train):   0%|          | 0/3000 [00:00<?, ? examples/s]Computing length of the text(train):  23%|██▎       | 694/3000 [00:00<00:00, 6869.87 examples/s]Computing length of the text(train):  53%|█████▎    | 1578/3000 [00:00<00:00, 6210.40 examples/s]Computing length of the text(train): 100%|██████████| 3000/3000 [00:00<00:00, 8778.79 examples/s]Computing length of the text(train): 100%|██████████| 3000/3000 [00:00<00:00, 6054.20 examples/s]
Computing length of the text(test):   0%|          | 0/2000 [00:00<?, ? examples/s]Computing length of the text(test):  98%|█████████▊| 1968/2000 [00:00<00:00, 19565.41 examples/s]Computing length of the text(test): 100%|██████████| 2000/2000 [00:00<00:00, 10982.10 examples/s]
[04/17/25 04:40:55] INFO     Average Length of the string in           run.py:20
                             dataset:(144.44433333333333, 142.3665)             
                    INFO     Data preview: {'text': ' with India to    run.py:21
                             advance a peace process that has faltered          
                             recently over Kashmir, while a more                
                             reserved India said progress must be               
                             measured "step-by-step".Car Bomb'}                 
                             {'text': ' Anthrax Vaccine (Reuters)               
                             Reuters - California vaccine maker VaxGen          
                             Inc.\\will make a new and improved                 
                             version of the anthrax vaccine for\\use            
                             in'}                                               
                    INFO     Loading model in int8: False   finetuned_llms.py:95
                             or half: True                                      
[04/17/25 04:40:56] INFO     > Loading the provided        finetuned_llms.py:113
                             ./ft_llms/Qwen/Qwen2.5-1.5B/a                      
                             g_news/bs32/self_prompt/check                      
                             point-28 checkpoint from                           
                             './ft_llms/Qwen/Qwen2.5-1.5B/                      
                             ag_news/bs32/self_prompt/chec                      
                             kpoint-28'.                                        
If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`
[04/17/25 04:41:00] INFO     Evaluating train set:                    MIA.py:140
Evaluating spv_mia:   0%|          | 0/3000 [00:00<?, ? examples/s]Evaluating spv_mia:   2%|▏         | 64/3000 [00:13<10:04,  4.85 examples/s]Evaluating spv_mia:   4%|▍         | 128/3000 [00:26<10:07,  4.73 examples/s]Evaluating spv_mia:   6%|▋         | 192/3000 [00:40<09:46,  4.79 examples/s]Evaluating spv_mia:   9%|▊         | 256/3000 [00:55<10:07,  4.52 examples/s]Evaluating spv_mia:  11%|█         | 320/3000 [01:09<09:47,  4.56 examples/s]Evaluating spv_mia:  13%|█▎        | 384/3000 [01:24<09:54,  4.40 examples/s]Evaluating spv_mia:  15%|█▍        | 448/3000 [01:39<09:38,  4.41 examples/s]Evaluating spv_mia:  17%|█▋        | 512/3000 [01:56<09:57,  4.16 examples/s]Evaluating spv_mia:  19%|█▉        | 576/3000 [02:09<09:17,  4.35 examples/s]Evaluating spv_mia:  21%|██▏       | 640/3000 [02:24<09:02,  4.35 examples/s]Evaluating spv_mia:  23%|██▎       | 704/3000 [02:39<08:52,  4.31 examples/s]Evaluating spv_mia:  26%|██▌       | 768/3000 [02:56<08:54,  4.18 examples/s]Evaluating spv_mia:  28%|██▊       | 832/3000 [03:10<08:27,  4.27 examples/s]Evaluating spv_mia:  30%|██▉       | 896/3000 [03:25<08:18,  4.22 examples/s]Evaluating spv_mia:  32%|███▏      | 960/3000 [03:40<07:56,  4.29 examples/s]Evaluating spv_mia:  34%|███▍      | 1024/3000 [03:55<07:48,  4.22 examples/s]Evaluating spv_mia:  36%|███▋      | 1088/3000 [04:10<07:23,  4.31 examples/s]Evaluating spv_mia:  38%|███▊      | 1152/3000 [04:24<07:08,  4.31 examples/s]Evaluating spv_mia:  41%|████      | 1216/3000 [04:40<06:58,  4.26 examples/s]Evaluating spv_mia:  43%|████▎     | 1280/3000 [04:55<06:43,  4.26 examples/s]Evaluating spv_mia:  45%|████▍     | 1344/3000 [05:08<06:16,  4.40 examples/s]Evaluating spv_mia:  47%|████▋     | 1408/3000 [05:23<06:03,  4.38 examples/s]Evaluating spv_mia:  49%|████▉     | 1472/3000 [05:38<05:53,  4.32 examples/s]Evaluating spv_mia:  51%|█████     | 1536/3000 [05:53<05:40,  4.30 examples/s]Evaluating spv_mia:  53%|█████▎    | 1600/3000 [06:08<05:25,  4.30 examples/s]Evaluating spv_mia:  55%|█████▌    | 1664/3000 [06:22<05:01,  4.44 examples/s]Evaluating spv_mia:  58%|█████▊    | 1728/3000 [06:37<04:53,  4.33 examples/s]Evaluating spv_mia:  60%|█████▉    | 1792/3000 [06:52<04:36,  4.36 examples/s]Evaluating spv_mia:  62%|██████▏   | 1856/3000 [07:07<04:23,  4.34 examples/s]Evaluating spv_mia:  64%|██████▍   | 1920/3000 [07:21<04:06,  4.38 examples/s]Evaluating spv_mia:  66%|██████▌   | 1984/3000 [07:36<03:53,  4.34 examples/s]Evaluating spv_mia:  68%|██████▊   | 2048/3000 [07:50<03:37,  4.38 examples/s]Evaluating spv_mia:  70%|███████   | 2112/3000 [08:05<03:24,  4.35 examples/s]Evaluating spv_mia:  73%|███████▎  | 2176/3000 [08:19<03:07,  4.39 examples/s]Evaluating spv_mia:  75%|███████▍  | 2240/3000 [08:33<02:51,  4.44 examples/s]Evaluating spv_mia:  77%|███████▋  | 2304/3000 [08:48<02:37,  4.42 examples/s]Evaluating spv_mia:  79%|███████▉  | 2368/3000 [09:03<02:24,  4.37 examples/s]Evaluating spv_mia:  81%|████████  | 2432/3000 [09:21<02:18,  4.09 examples/s]Evaluating spv_mia:  83%|████████▎ | 2496/3000 [09:39<02:08,  3.94 examples/s]Evaluating spv_mia:  85%|████████▌ | 2560/3000 [09:56<01:54,  3.84 examples/s]Evaluating spv_mia:  87%|████████▋ | 2624/3000 [10:12<01:36,  3.89 examples/s]Evaluating spv_mia:  90%|████████▉ | 2688/3000 [10:30<01:21,  3.83 examples/s]Evaluating spv_mia:  92%|█████████▏| 2752/3000 [10:45<01:03,  3.92 examples/s]Evaluating spv_mia:  94%|█████████▍| 2816/3000 [11:00<00:45,  4.06 examples/s]Evaluating spv_mia:  96%|█████████▌| 2880/3000 [11:15<00:29,  4.10 examples/s]Evaluating spv_mia:  98%|█████████▊| 2944/3000 [11:29<00:13,  4.18 examples/s]Evaluating spv_mia: 100%|██████████| 3000/3000 [11:42<00:00,  4.21 examples/s]Evaluating spv_mia: 100%|██████████| 3000/3000 [11:42<00:00,  4.27 examples/s]
[04/17/25 04:53:14] INFO     Train avg score: -1.4705490315258503     MIA.py:144
                    INFO     Evaluating test set:                     MIA.py:155
Evaluating spv_mia:   0%|          | 0/2000 [00:00<?, ? examples/s]Evaluating spv_mia:   3%|▎         | 64/2000 [00:14<07:20,  4.39 examples/s]Evaluating spv_mia:   6%|▋         | 128/2000 [00:29<07:14,  4.31 examples/s]Evaluating spv_mia:  10%|▉         | 192/2000 [00:44<06:55,  4.36 examples/s]Evaluating spv_mia:  13%|█▎        | 256/2000 [00:59<06:51,  4.24 examples/s]Evaluating spv_mia:  16%|█▌        | 320/2000 [01:14<06:27,  4.33 examples/s]Evaluating spv_mia:  19%|█▉        | 384/2000 [01:27<06:04,  4.44 examples/s]Evaluating spv_mia:  22%|██▏       | 448/2000 [01:42<05:49,  4.44 examples/s]Evaluating spv_mia:  26%|██▌       | 512/2000 [01:56<05:35,  4.44 examples/s]Evaluating spv_mia:  29%|██▉       | 576/2000 [02:11<05:20,  4.44 examples/s]Evaluating spv_mia:  32%|███▏      | 640/2000 [02:25<05:09,  4.39 examples/s]Evaluating spv_mia:  35%|███▌      | 704/2000 [02:40<04:56,  4.37 examples/s]Evaluating spv_mia:  38%|███▊      | 768/2000 [02:56<04:48,  4.27 examples/s]Evaluating spv_mia:  42%|████▏     | 832/2000 [03:10<04:30,  4.32 examples/s]Evaluating spv_mia:  45%|████▍     | 896/2000 [03:25<04:16,  4.31 examples/s]Evaluating spv_mia:  48%|████▊     | 960/2000 [03:40<04:01,  4.31 examples/s]Evaluating spv_mia:  51%|█████     | 1024/2000 [03:56<03:52,  4.20 examples/s]Evaluating spv_mia:  54%|█████▍    | 1088/2000 [04:10<03:29,  4.35 examples/s]Evaluating spv_mia:  58%|█████▊    | 1152/2000 [04:26<03:20,  4.23 examples/s]Evaluating spv_mia:  61%|██████    | 1216/2000 [04:41<03:03,  4.26 examples/s]Evaluating spv_mia:  64%|██████▍   | 1280/2000 [04:57<02:54,  4.13 examples/s]Evaluating spv_mia:  67%|██████▋   | 1344/2000 [05:10<02:29,  4.39 examples/s]Evaluating spv_mia:  70%|███████   | 1408/2000 [05:26<02:18,  4.28 examples/s]Evaluating spv_mia:  74%|███████▎  | 1472/2000 [05:40<02:01,  4.34 examples/s]Evaluating spv_mia:  77%|███████▋  | 1536/2000 [05:54<01:46,  4.37 examples/s]Evaluating spv_mia:  80%|████████  | 1600/2000 [06:09<01:30,  4.40 examples/s]Evaluating spv_mia:  83%|████████▎ | 1664/2000 [06:24<01:17,  4.36 examples/s]Evaluating spv_mia:  86%|████████▋ | 1728/2000 [06:39<01:03,  4.31 examples/s]Evaluating spv_mia:  90%|████████▉ | 1792/2000 [06:54<00:48,  4.29 examples/s]Evaluating spv_mia:  93%|█████████▎| 1856/2000 [07:08<00:32,  4.37 examples/s]Evaluating spv_mia:  96%|█████████▌| 1920/2000 [07:23<00:18,  4.35 examples/s]Evaluating spv_mia:  99%|█████████▉| 1984/2000 [07:38<00:03,  4.33 examples/s]Evaluating spv_mia: 100%|██████████| 2000/2000 [07:43<00:00,  4.11 examples/s]Evaluating spv_mia: 100%|██████████| 2000/2000 [07:43<00:00,  4.31 examples/s]
[04/17/25 05:01:29] INFO     Test avg score: -0.5549359560757875      MIA.py:160
Saving the dataset (0/1 shards):   0%|          | 0/3000 [00:00<?, ? examples/s]Saving the dataset (1/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 57812.86 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 55350.13 examples/s]
Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]Saving the dataset (1/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 63586.19 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 59453.62 examples/s]
                    INFO     Neighbor data saved to                   MIA.py:279
                             ./data/neighbor_data/Qwen2TokenizerFast/           
                             ag_news/bs32/spv_mia                               
[04/17/25 05:01:30] INFO     =========ENDING==========                 run.py:41
                    INFO                                             0 run.py:42
                             block_size                             32          
                             metric                            spv_mia          
                             train_score                     -1.470549          
                             test_score                      -0.554936          
                             acc                                 0.817          
                             auc                              0.975405          
                             TPR@0.1%FPR(0.00100)             0.090667          
                             TPR@0.5%FPR(0.00500)                0.214          
                             TPR@1.0%FPR(0.01000)             0.441667          
                             TPR@5.0%FPR(0.05000)             0.894333          
                             FPR@99.0%TPR(0.99000)                 0.2          
                             FPR@95.0%TPR(0.94867)               0.083          
                             n_perturbed                            20          
                             n_neighbor                             25          
                             mask_ratio                            0.2          
                             refer_model              Qwen2ForCausalLM          
                             mask_model             RobertaForCausalLM          
                    INFO     Total time: 1359.2 seconds                run.py:45
Start running the experiment.
>>>> [CUDA]Cuda visible devices: 7
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `1`
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
[04/17/25 05:01:42] INFO     Loading model in int8: False   finetuned_llms.py:95
                             or half: True                                      
[04/17/25 05:01:43] INFO     > Loading the provided        finetuned_llms.py:113
                             ./ft_llms/Qwen/Qwen2.5-1.5B/a                      
                             g_news/bs32/target_base/check                      
                             point-230 checkpoint from                          
                             './ft_llms/Qwen/Qwen2.5-1.5B/                      
                             ag_news/bs32/target_base/chec                      
                             kpoint-230'.                                       
[04/17/25 05:01:59] INFO     Train dataset columns: ['text',     provider.py:149
                             'label'], select text column: text                 
                    INFO     Block size: 32, max buffer size:    provider.py:162
                             117964.8                                           
[04/17/25 05:01:59] INFO     Using split dataset.                  factory.py:35
Computing length of the text(train):   0%|          | 0/3000 [00:00<?, ? examples/s]Computing length of the text(train):  27%|██▋       | 820/3000 [00:00<00:00, 8143.53 examples/s]Computing length of the text(train):  68%|██████▊   | 2044/3000 [00:00<00:00, 10543.02 examples/s]Computing length of the text(train): 100%|██████████| 3000/3000 [00:00<00:00, 10208.09 examples/s]
Computing length of the text(test):   0%|          | 0/2000 [00:00<?, ? examples/s]Computing length of the text(test):  35%|███▌      | 703/2000 [00:00<00:00, 6786.15 examples/s]Computing length of the text(test):  88%|████████▊ | 1758/2000 [00:00<00:00, 8963.25 examples/s]Computing length of the text(test): 100%|██████████| 2000/2000 [00:00<00:00, 8454.44 examples/s]
[04/17/25 05:02:00] INFO     Average Length of the string in           run.py:20
                             dataset:(144.44433333333333, 142.3665)             
                    INFO     Data preview: {'text': ' with India to    run.py:21
                             advance a peace process that has faltered          
                             recently over Kashmir, while a more                
                             reserved India said progress must be               
                             measured "step-by-step".Car Bomb'}                 
                             {'text': ' Anthrax Vaccine (Reuters)               
                             Reuters - California vaccine maker VaxGen          
                             Inc.\\will make a new and improved                 
                             version of the anthrax vaccine for\\use            
                             in'}                                               
                    INFO     Loading model in int8: False   finetuned_llms.py:95
                             or half: True                                      
[04/17/25 05:02:01] INFO     > Loading the provided        finetuned_llms.py:113
                             ./ft_llms/Qwen/Qwen2.5-1.5B/a                      
                             g_news/bs32/self_prompt/check                      
                             point-28 checkpoint from                           
                             './ft_llms/Qwen/Qwen2.5-1.5B/                      
                             ag_news/bs32/self_prompt/chec                      
                             kpoint-28'.                                        
If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`
[04/17/25 05:02:05] INFO     Evaluating train set:                    MIA.py:140
Evaluating spv_mia:   0%|          | 0/3000 [00:00<?, ? examples/s]Evaluating spv_mia:   2%|▏         | 64/3000 [00:23<18:04,  2.71 examples/s]Evaluating spv_mia:   4%|▍         | 128/3000 [00:46<17:24,  2.75 examples/s]Evaluating spv_mia:   6%|▋         | 192/3000 [01:08<16:41,  2.80 examples/s]Evaluating spv_mia:   9%|▊         | 256/3000 [01:33<16:54,  2.71 examples/s]Evaluating spv_mia:  11%|█         | 320/3000 [01:57<16:30,  2.71 examples/s]Evaluating spv_mia:  13%|█▎        | 384/3000 [02:22<16:22,  2.66 examples/s]Evaluating spv_mia:  15%|█▍        | 448/3000 [02:45<15:50,  2.68 examples/s]Evaluating spv_mia:  17%|█▋        | 512/3000 [03:10<15:34,  2.66 examples/s]Evaluating spv_mia:  19%|█▉        | 576/3000 [03:35<15:23,  2.63 examples/s]Evaluating spv_mia:  21%|██▏       | 640/3000 [03:56<14:24,  2.73 examples/s]Evaluating spv_mia:  23%|██▎       | 704/3000 [04:21<14:18,  2.68 examples/s]Evaluating spv_mia:  26%|██▌       | 768/3000 [04:45<13:51,  2.68 examples/s]Evaluating spv_mia:  28%|██▊       | 832/3000 [05:10<13:40,  2.64 examples/s]Evaluating spv_mia:  30%|██▉       | 896/3000 [05:33<13:03,  2.68 examples/s]Evaluating spv_mia:  32%|███▏      | 960/3000 [05:53<12:06,  2.81 examples/s]Evaluating spv_mia:  34%|███▍      | 1024/3000 [06:20<12:19,  2.67 examples/s]Evaluating spv_mia:  36%|███▋      | 1088/3000 [06:44<11:57,  2.66 examples/s]Evaluating spv_mia:  38%|███▊      | 1152/3000 [07:09<11:44,  2.62 examples/s]Evaluating spv_mia:  41%|████      | 1216/3000 [07:33<11:12,  2.65 examples/s]Evaluating spv_mia:  43%|████▎     | 1280/3000 [07:56<10:42,  2.68 examples/s]Evaluating spv_mia:  45%|████▍     | 1344/3000 [08:17<09:51,  2.80 examples/s]Evaluating spv_mia:  47%|████▋     | 1408/3000 [08:41<09:39,  2.75 examples/s]Evaluating spv_mia:  49%|████▉     | 1472/3000 [09:08<09:42,  2.63 examples/s]Evaluating spv_mia:  51%|█████     | 1536/3000 [09:31<09:10,  2.66 examples/s]Evaluating spv_mia:  53%|█████▎    | 1600/3000 [09:57<08:56,  2.61 examples/s]Evaluating spv_mia:  55%|█████▌    | 1664/3000 [10:16<08:01,  2.78 examples/s]Evaluating spv_mia:  58%|█████▊    | 1728/3000 [10:45<08:10,  2.59 examples/s]Evaluating spv_mia:  60%|█████▉    | 1792/3000 [11:14<08:09,  2.47 examples/s]Evaluating spv_mia:  62%|██████▏   | 1856/3000 [11:43<08:00,  2.38 examples/s]Evaluating spv_mia:  64%|██████▍   | 1920/3000 [12:11<07:38,  2.36 examples/s]Evaluating spv_mia:  66%|██████▌   | 1984/3000 [12:35<06:58,  2.43 examples/s]Evaluating spv_mia:  68%|██████▊   | 2048/3000 [13:00<06:24,  2.48 examples/s]Evaluating spv_mia:  70%|███████   | 2112/3000 [13:25<05:53,  2.51 examples/s]Evaluating spv_mia:  73%|███████▎  | 2176/3000 [13:49<05:25,  2.53 examples/s]Evaluating spv_mia:  75%|███████▍  | 2240/3000 [14:10<04:44,  2.67 examples/s]Evaluating spv_mia:  77%|███████▋  | 2304/3000 [14:36<04:27,  2.60 examples/s]Evaluating spv_mia:  79%|███████▉  | 2368/3000 [15:00<04:01,  2.62 examples/s]Evaluating spv_mia:  81%|████████  | 2432/3000 [15:25<03:37,  2.61 examples/s]Evaluating spv_mia:  83%|████████▎ | 2496/3000 [15:49<03:12,  2.62 examples/s]Evaluating spv_mia:  85%|████████▌ | 2560/3000 [16:14<02:47,  2.62 examples/s]Evaluating spv_mia:  87%|████████▋ | 2624/3000 [16:37<02:21,  2.66 examples/s]Evaluating spv_mia:  90%|████████▉ | 2688/3000 [17:01<01:57,  2.66 examples/s]Evaluating spv_mia:  92%|█████████▏| 2752/3000 [17:23<01:30,  2.73 examples/s]Evaluating spv_mia:  94%|█████████▍| 2816/3000 [17:47<01:07,  2.71 examples/s]Evaluating spv_mia:  96%|█████████▌| 2880/3000 [18:11<00:44,  2.69 examples/s]Evaluating spv_mia:  98%|█████████▊| 2944/3000 [18:38<00:21,  2.60 examples/s]Evaluating spv_mia: 100%|██████████| 3000/3000 [19:00<00:00,  2.58 examples/s]Evaluating spv_mia: 100%|██████████| 3000/3000 [19:00<00:00,  2.63 examples/s]
[04/17/25 05:21:42] INFO     Train avg score: -1.5160017772813639     MIA.py:144
                    INFO     Evaluating test set:                     MIA.py:155
Evaluating spv_mia:   0%|          | 0/2000 [00:00<?, ? examples/s]Evaluating spv_mia:   3%|▎         | 64/2000 [00:23<12:03,  2.67 examples/s]Evaluating spv_mia:   6%|▋         | 128/2000 [00:49<12:04,  2.58 examples/s]Evaluating spv_mia:  10%|▉         | 192/2000 [01:12<11:22,  2.65 examples/s]Evaluating spv_mia:  13%|█▎        | 256/2000 [01:36<10:56,  2.66 examples/s]Evaluating spv_mia:  16%|█▌        | 320/2000 [02:00<10:28,  2.67 examples/s]Evaluating spv_mia:  19%|█▉        | 384/2000 [02:23<09:59,  2.70 examples/s]Evaluating spv_mia:  22%|██▏       | 448/2000 [02:52<10:17,  2.51 examples/s]Evaluating spv_mia:  26%|██▌       | 512/2000 [03:17<09:48,  2.53 examples/s]Evaluating spv_mia:  29%|██▉       | 576/2000 [03:47<09:52,  2.40 examples/s]Evaluating spv_mia:  32%|███▏      | 640/2000 [04:11<09:08,  2.48 examples/s]Evaluating spv_mia:  35%|███▌      | 704/2000 [04:37<08:48,  2.45 examples/s]Evaluating spv_mia:  38%|███▊      | 768/2000 [05:01<08:09,  2.52 examples/s]Evaluating spv_mia:  42%|████▏     | 832/2000 [05:28<07:50,  2.48 examples/s]Evaluating spv_mia:  45%|████▍     | 896/2000 [05:51<07:11,  2.56 examples/s]Evaluating spv_mia:  48%|████▊     | 960/2000 [06:16<06:43,  2.58 examples/s]Evaluating spv_mia:  51%|█████     | 1024/2000 [06:39<06:12,  2.62 examples/s]Evaluating spv_mia:  54%|█████▍    | 1088/2000 [07:03<05:45,  2.64 examples/s]Evaluating spv_mia:  58%|█████▊    | 1152/2000 [07:29<05:28,  2.58 examples/s]Evaluating spv_mia:  61%|██████    | 1216/2000 [07:52<04:58,  2.63 examples/s]Evaluating spv_mia:  64%|██████▍   | 1280/2000 [08:17<04:36,  2.61 examples/s]Evaluating spv_mia:  67%|██████▋   | 1344/2000 [08:38<03:59,  2.74 examples/s]Evaluating spv_mia:  70%|███████   | 1408/2000 [09:02<03:39,  2.70 examples/s]Evaluating spv_mia:  74%|███████▎  | 1472/2000 [09:24<03:11,  2.76 examples/s]Evaluating spv_mia:  77%|███████▋  | 1536/2000 [09:45<02:41,  2.87 examples/s]Evaluating spv_mia:  80%|████████  | 1600/2000 [10:09<02:23,  2.78 examples/s]Evaluating spv_mia:  83%|████████▎ | 1664/2000 [10:32<02:00,  2.78 examples/s]Evaluating spv_mia:  86%|████████▋ | 1728/2000 [10:57<01:39,  2.72 examples/s]Evaluating spv_mia:  90%|████████▉ | 1792/2000 [11:19<01:15,  2.76 examples/s]Evaluating spv_mia:  93%|█████████▎| 1856/2000 [11:42<00:52,  2.76 examples/s]Evaluating spv_mia:  96%|█████████▌| 1920/2000 [12:06<00:29,  2.75 examples/s]Evaluating spv_mia:  99%|█████████▉| 1984/2000 [12:28<00:05,  2.80 examples/s]Evaluating spv_mia: 100%|██████████| 2000/2000 [12:35<00:00,  2.74 examples/s]Evaluating spv_mia: 100%|██████████| 2000/2000 [12:35<00:00,  2.65 examples/s]
[04/17/25 05:34:48] INFO     Test avg score: -0.5832853122502566      MIA.py:160
Saving the dataset (0/1 shards):   0%|          | 0/3000 [00:00<?, ? examples/s]Saving the dataset (1/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 40587.16 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 39127.67 examples/s]
Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]Saving the dataset (1/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 40562.69 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 37941.19 examples/s]
[04/17/25 05:34:49] INFO     Neighbor data saved to                   MIA.py:279
                             ./data/neighbor_data/Qwen2TokenizerFast/           
                             ag_news/bs32/spv_mia                               
                    INFO     =========ENDING==========                 run.py:41
                    INFO                                             0 run.py:42
                             block_size                             32          
                             metric                            spv_mia          
                             train_score                     -1.516002          
                             test_score                      -0.583285          
                             acc                                0.8168          
                             auc                              0.976792          
                             TPR@0.1%FPR(0.00100)                0.085          
                             TPR@0.5%FPR(0.00500)             0.222333          
                             TPR@1.0%FPR(0.01000)                0.437          
                             TPR@5.0%FPR(0.05000)             0.894667          
                             FPR@99.0%TPR(0.99000)              0.1975          
                             FPR@95.0%TPR(0.94800)              0.0745          
                             n_perturbed                            50          
                             n_neighbor                             25          
                             mask_ratio                            0.2          
                             refer_model              Qwen2ForCausalLM          
                             mask_model             RobertaForCausalLM          
                    INFO     Total time: 1987.2 seconds                run.py:45
Start running the experiment.
>>>> [CUDA]Cuda visible devices: 7
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `1`
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
[04/17/25 05:35:02] INFO     Loading model in int8: False   finetuned_llms.py:95
                             or half: True                                      
[04/17/25 05:35:03] INFO     > Loading the provided        finetuned_llms.py:113
                             ./ft_llms/Qwen/Qwen2.5-1.5B/a                      
                             g_news/bs64/target_base/check                      
                             point-184 checkpoint from                          
                             './ft_llms/Qwen/Qwen2.5-1.5B/                      
                             ag_news/bs64/target_base/chec                      
                             kpoint-184'.                                       
[04/17/25 05:35:17] INFO     Train dataset columns: ['text',     provider.py:149
                             'label'], select text column: text                 
                    INFO     Block size: 64, max buffer size:    provider.py:162
                             235929.6                                           
[04/17/25 05:35:17] INFO     Using split dataset.                  factory.py:35
Computing length of the text(train):   0%|          | 0/3000 [00:00<?, ? examples/s]Computing length of the text(train):  36%|███▌      | 1079/3000 [00:00<00:00, 10687.75 examples/s]Computing length of the text(train): 100%|██████████| 3000/3000 [00:00<00:00, 11632.80 examples/s]Computing length of the text(train): 100%|██████████| 3000/3000 [00:00<00:00, 9835.83 examples/s] 
Computing length of the text(test):   0%|          | 0/2000 [00:00<?, ? examples/s]Computing length of the text(test):  55%|█████▍    | 1099/2000 [00:00<00:00, 10889.35 examples/s]Computing length of the text(test): 100%|██████████| 2000/2000 [00:00<00:00, 9392.82 examples/s] 
[04/17/25 05:35:18] INFO     Average Length of the string in           run.py:20
                             dataset:(285.97833333333335, 283.5965)             
                    INFO     Data preview: {'text': ' Hamadeh was      run.py:21
                             wounded Friday when his car was targeted           
                             by a remote-controlled bomb near his               
                             home. He suffered only minor injuries,             
                             but his driver was killed and a bodyguard          
                             was seriously hurt.PeopleSoft Ousts CEO            
                             Who Battled Oracle  In NEW YORK story              
                             headlined "PeopleSoft ousts CEO amid '}            
                             {'text': " anger A computer firm is                
                             criticised by the Kennedy family for               
                             producing a game recreating the                    
                             president's death.PeopleSoft Won #39;t Go          
                             Quietly A major battle is over, but the            
                             war for PeopleSoft (PSFT:Nasdaq - news -           
                             research) rages on. Executives of the              
                             business"}                                         
                    INFO     Loading model in int8: False   finetuned_llms.py:95
                             or half: True                                      
                    INFO     > Loading the provided        finetuned_llms.py:113
                             ./ft_llms/Qwen/Qwen2.5-1.5B/a                      
                             g_news/bs64/self_prompt/check                      
                             point-28 checkpoint from                           
                             './ft_llms/Qwen/Qwen2.5-1.5B/                      
                             ag_news/bs64/self_prompt/chec                      
                             kpoint-28'.                                        
If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`
[04/17/25 05:35:22] INFO     Evaluating train set:                    MIA.py:140
Evaluating spv_mia:   0%|          | 0/3000 [00:00<?, ? examples/s]Evaluating spv_mia:   2%|▏         | 64/3000 [00:23<18:08,  2.70 examples/s]Evaluating spv_mia:   4%|▍         | 128/3000 [00:48<18:20,  2.61 examples/s]Evaluating spv_mia:   6%|▋         | 192/3000 [01:12<17:35,  2.66 examples/s]Evaluating spv_mia:   9%|▊         | 256/3000 [01:35<17:00,  2.69 examples/s]Evaluating spv_mia:  11%|█         | 320/3000 [01:57<16:09,  2.77 examples/s]Evaluating spv_mia:  13%|█▎        | 384/3000 [02:20<15:43,  2.77 examples/s]Evaluating spv_mia:  15%|█▍        | 448/3000 [02:41<14:50,  2.87 examples/s]Evaluating spv_mia:  17%|█▋        | 512/3000 [03:02<14:16,  2.90 examples/s]Evaluating spv_mia:  19%|█▉        | 576/3000 [03:24<13:53,  2.91 examples/s]Evaluating spv_mia:  21%|██▏       | 640/3000 [03:45<13:18,  2.96 examples/s]Evaluating spv_mia:  23%|██▎       | 704/3000 [04:07<12:57,  2.95 examples/s]Evaluating spv_mia:  26%|██▌       | 768/3000 [04:29<12:46,  2.91 examples/s]Evaluating spv_mia:  28%|██▊       | 832/3000 [04:52<12:27,  2.90 examples/s]Evaluating spv_mia:  30%|██▉       | 896/3000 [05:13<11:55,  2.94 examples/s]Evaluating spv_mia:  32%|███▏      | 960/3000 [05:34<11:30,  2.95 examples/s]Evaluating spv_mia:  34%|███▍      | 1024/3000 [05:56<11:10,  2.95 examples/s]Evaluating spv_mia:  36%|███▋      | 1088/3000 [06:17<10:40,  2.99 examples/s]Evaluating spv_mia:  38%|███▊      | 1152/3000 [06:40<10:33,  2.92 examples/s]Evaluating spv_mia:  41%|████      | 1216/3000 [07:03<10:16,  2.89 examples/s]Evaluating spv_mia:  43%|████▎     | 1280/3000 [07:25<09:59,  2.87 examples/s]Evaluating spv_mia:  45%|████▍     | 1344/3000 [07:49<09:45,  2.83 examples/s]Evaluating spv_mia:  47%|████▋     | 1408/3000 [08:11<09:21,  2.84 examples/s]Evaluating spv_mia:  49%|████▉     | 1472/3000 [08:32<08:49,  2.89 examples/s]Evaluating spv_mia:  51%|█████     | 1536/3000 [08:54<08:24,  2.90 examples/s]Evaluating spv_mia:  53%|█████▎    | 1600/3000 [09:17<08:06,  2.88 examples/s]Evaluating spv_mia:  55%|█████▌    | 1664/3000 [09:38<07:36,  2.93 examples/s]Evaluating spv_mia:  58%|█████▊    | 1728/3000 [10:01<07:19,  2.89 examples/s]Evaluating spv_mia:  60%|█████▉    | 1792/3000 [10:23<07:00,  2.87 examples/s]Evaluating spv_mia:  62%|██████▏   | 1856/3000 [10:45<06:36,  2.88 examples/s]Evaluating spv_mia:  64%|██████▍   | 1920/3000 [11:07<06:14,  2.88 examples/s]Evaluating spv_mia:  66%|██████▌   | 1984/3000 [11:34<06:13,  2.72 examples/s]Evaluating spv_mia:  68%|██████▊   | 2048/3000 [12:00<05:59,  2.65 examples/s]Evaluating spv_mia:  70%|███████   | 2112/3000 [12:24<05:37,  2.63 examples/s]Evaluating spv_mia:  73%|███████▎  | 2176/3000 [12:50<05:18,  2.59 examples/s]Evaluating spv_mia:  75%|███████▍  | 2240/3000 [13:13<04:48,  2.64 examples/s]Evaluating spv_mia:  77%|███████▋  | 2304/3000 [13:38<04:24,  2.63 examples/s]Evaluating spv_mia:  79%|███████▉  | 2368/3000 [13:59<03:50,  2.74 examples/s]Evaluating spv_mia:  81%|████████  | 2432/3000 [14:20<03:22,  2.80 examples/s]Evaluating spv_mia:  83%|████████▎ | 2496/3000 [14:42<02:56,  2.86 examples/s]Evaluating spv_mia:  85%|████████▌ | 2560/3000 [15:05<02:35,  2.84 examples/s]Evaluating spv_mia:  87%|████████▋ | 2624/3000 [15:27<02:12,  2.84 examples/s]Evaluating spv_mia:  90%|████████▉ | 2688/3000 [15:51<01:51,  2.81 examples/s]Evaluating spv_mia:  92%|█████████▏| 2752/3000 [16:14<01:28,  2.80 examples/s]Evaluating spv_mia:  94%|█████████▍| 2816/3000 [16:37<01:06,  2.78 examples/s]Evaluating spv_mia:  96%|█████████▌| 2880/3000 [16:58<00:42,  2.84 examples/s]Evaluating spv_mia:  98%|█████████▊| 2944/3000 [17:22<00:19,  2.82 examples/s]Evaluating spv_mia: 100%|██████████| 3000/3000 [17:39<00:00,  2.90 examples/s]Evaluating spv_mia: 100%|██████████| 3000/3000 [17:39<00:00,  2.83 examples/s]
[04/17/25 05:53:32] INFO     Train avg score: -1.1405481755336127     MIA.py:144
                    INFO     Evaluating test set:                     MIA.py:155
Evaluating spv_mia:   0%|          | 0/2000 [00:00<?, ? examples/s]Evaluating spv_mia:   3%|▎         | 64/2000 [00:20<10:19,  3.13 examples/s]Evaluating spv_mia:   6%|▋         | 128/2000 [00:43<10:41,  2.92 examples/s]Evaluating spv_mia:  10%|▉         | 192/2000 [01:06<10:40,  2.82 examples/s]Evaluating spv_mia:  13%|█▎        | 256/2000 [01:26<09:46,  2.98 examples/s]Evaluating spv_mia:  16%|█▌        | 320/2000 [01:49<09:35,  2.92 examples/s]Evaluating spv_mia:  19%|█▉        | 384/2000 [02:14<09:37,  2.80 examples/s]Evaluating spv_mia:  22%|██▏       | 448/2000 [02:37<09:17,  2.78 examples/s]Evaluating spv_mia:  26%|██▌       | 512/2000 [03:00<08:56,  2.78 examples/s]Evaluating spv_mia:  29%|██▉       | 576/2000 [03:21<08:17,  2.86 examples/s]Evaluating spv_mia:  32%|███▏      | 640/2000 [03:44<08:02,  2.82 examples/s]Evaluating spv_mia:  35%|███▌      | 704/2000 [04:07<07:40,  2.82 examples/s]Evaluating spv_mia:  38%|███▊      | 768/2000 [04:29<07:15,  2.83 examples/s]Evaluating spv_mia:  42%|████▏     | 832/2000 [04:56<07:14,  2.69 examples/s]Evaluating spv_mia:  45%|████▍     | 896/2000 [05:22<07:04,  2.60 examples/s]Evaluating spv_mia:  48%|████▊     | 960/2000 [05:46<06:35,  2.63 examples/s]Evaluating spv_mia:  51%|█████     | 1024/2000 [06:12<06:15,  2.60 examples/s]Evaluating spv_mia:  54%|█████▍    | 1088/2000 [06:34<05:43,  2.66 examples/s]Evaluating spv_mia:  58%|█████▊    | 1152/2000 [06:58<05:17,  2.67 examples/s]Evaluating spv_mia:  61%|██████    | 1216/2000 [07:21<04:48,  2.71 examples/s]Evaluating spv_mia:  64%|██████▍   | 1280/2000 [07:46<04:30,  2.67 examples/s]Evaluating spv_mia:  67%|██████▋   | 1344/2000 [08:06<03:54,  2.79 examples/s]Evaluating spv_mia:  70%|███████   | 1408/2000 [08:28<03:29,  2.82 examples/s]Evaluating spv_mia:  74%|███████▎  | 1472/2000 [08:52<03:09,  2.78 examples/s]Evaluating spv_mia:  77%|███████▋  | 1536/2000 [09:15<02:46,  2.79 examples/s]Evaluating spv_mia:  80%|████████  | 1600/2000 [09:38<02:24,  2.77 examples/s]Evaluating spv_mia:  83%|████████▎ | 1664/2000 [09:59<01:57,  2.86 examples/s]Evaluating spv_mia:  86%|████████▋ | 1728/2000 [10:20<01:33,  2.92 examples/s]Evaluating spv_mia:  90%|████████▉ | 1792/2000 [10:42<01:12,  2.89 examples/s]Evaluating spv_mia:  93%|█████████▎| 1856/2000 [11:04<00:49,  2.92 examples/s]Evaluating spv_mia:  96%|█████████▌| 1920/2000 [11:27<00:27,  2.86 examples/s]Evaluating spv_mia:  99%|█████████▉| 1984/2000 [11:49<00:05,  2.88 examples/s]Evaluating spv_mia: 100%|██████████| 2000/2000 [11:56<00:00,  2.81 examples/s]Evaluating spv_mia: 100%|██████████| 2000/2000 [11:56<00:00,  2.79 examples/s]
[04/17/25 06:05:59] INFO     Test avg score: -0.548584717169404       MIA.py:160
Saving the dataset (0/1 shards):   0%|          | 0/3000 [00:00<?, ? examples/s]Saving the dataset (1/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 31144.28 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 30190.63 examples/s]
Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]Saving the dataset (1/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 39853.71 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 37457.67 examples/s]
[04/17/25 06:06:00] INFO     Neighbor data saved to                   MIA.py:279
                             ./data/neighbor_data/Qwen2TokenizerFast/           
                             ag_news/bs64/spv_mia                               
                    INFO     =========ENDING==========                 run.py:41
                    INFO                                             0 run.py:42
                             block_size                             64          
                             metric                            spv_mia          
                             train_score                     -1.140548          
                             test_score                      -0.548585          
                             acc                                0.8192          
                             auc                              0.961516          
                             TPR@0.1%FPR(0.00100)             0.008667          
                             TPR@0.5%FPR(0.00500)                0.084          
                             TPR@1.0%FPR(0.01000)             0.147333          
                             TPR@5.0%FPR(0.05000)                0.803          
                             FPR@99.0%TPR(0.98933)              0.2715          
                             FPR@95.0%TPR(0.94967)               0.116          
                             n_perturbed                            20          
                             n_neighbor                             25          
                             mask_ratio                            0.2          
                             refer_model              Qwen2ForCausalLM          
                             mask_model             RobertaForCausalLM          
                    INFO     Total time: 1857.7 seconds                run.py:45
Start running the experiment.
>>>> [CUDA]Cuda visible devices: 7
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `1`
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
[04/17/25 06:06:12] INFO     Loading model in int8: False   finetuned_llms.py:95
                             or half: True                                      
[04/17/25 06:06:13] INFO     > Loading the provided        finetuned_llms.py:113
                             ./ft_llms/Qwen/Qwen2.5-1.5B/a                      
                             g_news/bs64/target_base/check                      
                             point-184 checkpoint from                          
                             './ft_llms/Qwen/Qwen2.5-1.5B/                      
                             ag_news/bs64/target_base/chec                      
                             kpoint-184'.                                       
[04/17/25 06:06:35] INFO     Train dataset columns: ['text',     provider.py:149
                             'label'], select text column: text                 
                    INFO     Block size: 64, max buffer size:    provider.py:162
                             235929.6                                           
[04/17/25 06:06:35] INFO     Using split dataset.                  factory.py:35
Computing length of the text(train):   0%|          | 0/3000 [00:00<?, ? examples/s]Computing length of the text(train):  34%|███▍      | 1022/3000 [00:00<00:00, 10171.80 examples/s]Computing length of the text(train):  74%|███████▍  | 2221/3000 [00:00<00:00, 11232.57 examples/s]Computing length of the text(train): 100%|██████████| 3000/3000 [00:00<00:00, 10221.21 examples/s]
Computing length of the text(test):   0%|          | 0/2000 [00:00<?, ? examples/s]Computing length of the text(test):  69%|██████▉   | 1379/2000 [00:00<00:00, 13675.08 examples/s]Computing length of the text(test): 100%|██████████| 2000/2000 [00:00<00:00, 11483.14 examples/s]
[04/17/25 06:06:36] INFO     Average Length of the string in           run.py:20
                             dataset:(285.97833333333335, 283.5965)             
                    INFO     Data preview: {'text': ' Hamadeh was      run.py:21
                             wounded Friday when his car was targeted           
                             by a remote-controlled bomb near his               
                             home. He suffered only minor injuries,             
                             but his driver was killed and a bodyguard          
                             was seriously hurt.PeopleSoft Ousts CEO            
                             Who Battled Oracle  In NEW YORK story              
                             headlined "PeopleSoft ousts CEO amid '}            
                             {'text': " anger A computer firm is                
                             criticised by the Kennedy family for               
                             producing a game recreating the                    
                             president's death.PeopleSoft Won #39;t Go          
                             Quietly A major battle is over, but the            
                             war for PeopleSoft (PSFT:Nasdaq - news -           
                             research) rages on. Executives of the              
                             business"}                                         
                    INFO     Loading model in int8: False   finetuned_llms.py:95
                             or half: True                                      
                    INFO     > Loading the provided        finetuned_llms.py:113
                             ./ft_llms/Qwen/Qwen2.5-1.5B/a                      
                             g_news/bs64/self_prompt/check                      
                             point-28 checkpoint from                           
                             './ft_llms/Qwen/Qwen2.5-1.5B/                      
                             ag_news/bs64/self_prompt/chec                      
                             kpoint-28'.                                        
If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`
[04/17/25 06:06:40] INFO     Evaluating train set:                    MIA.py:140
Evaluating spv_mia:   0%|          | 0/3000 [00:00<?, ? examples/s]Evaluating spv_mia:   2%|▏         | 64/3000 [00:42<32:43,  1.50 examples/s]Evaluating spv_mia:   4%|▍         | 128/3000 [01:31<34:42,  1.38 examples/s]Evaluating spv_mia:   6%|▋         | 192/3000 [02:14<32:49,  1.43 examples/s]Evaluating spv_mia:   9%|▊         | 256/3000 [02:58<31:48,  1.44 examples/s]Evaluating spv_mia:  11%|█         | 320/3000 [03:49<32:40,  1.37 examples/s]Evaluating spv_mia:  13%|█▎        | 384/3000 [04:39<32:35,  1.34 examples/s]Evaluating spv_mia:  15%|█▍        | 448/3000 [05:22<30:41,  1.39 examples/s]Evaluating spv_mia:  17%|█▋        | 512/3000 [06:05<29:13,  1.42 examples/s]Evaluating spv_mia:  19%|█▉        | 576/3000 [06:53<29:03,  1.39 examples/s]Evaluating spv_mia:  21%|██▏       | 640/3000 [07:36<27:43,  1.42 examples/s]Evaluating spv_mia:  23%|██▎       | 704/3000 [08:19<26:40,  1.43 examples/s]Evaluating spv_mia:  26%|██▌       | 768/3000 [09:07<26:32,  1.40 examples/s]Evaluating spv_mia:  28%|██▊       | 832/3000 [09:56<26:15,  1.38 examples/s]Evaluating spv_mia:  30%|██▉       | 896/3000 [10:39<24:59,  1.40 examples/s]Evaluating spv_mia:  32%|███▏      | 960/3000 [11:23<23:52,  1.42 examples/s]Evaluating spv_mia:  34%|███▍      | 1024/3000 [12:06<22:52,  1.44 examples/s]Evaluating spv_mia:  36%|███▋      | 1088/3000 [12:49<21:55,  1.45 examples/s]Evaluating spv_mia:  38%|███▊      | 1152/3000 [13:36<21:39,  1.42 examples/s]Evaluating spv_mia:  41%|████      | 1216/3000 [14:20<20:40,  1.44 examples/s]Evaluating spv_mia:  43%|████▎     | 1280/3000 [15:11<20:54,  1.37 examples/s]Evaluating spv_mia:  45%|████▍     | 1344/3000 [16:01<20:28,  1.35 examples/s]Evaluating spv_mia:  47%|████▋     | 1408/3000 [16:48<19:41,  1.35 examples/s]Evaluating spv_mia:  49%|████▉     | 1472/3000 [17:32<18:25,  1.38 examples/s]Evaluating spv_mia:  51%|█████     | 1536/3000 [18:15<17:19,  1.41 examples/s]Evaluating spv_mia:  53%|█████▎    | 1600/3000 [19:03<16:48,  1.39 examples/s]Evaluating spv_mia:  55%|█████▌    | 1664/3000 [19:46<15:44,  1.42 examples/s]Evaluating spv_mia:  58%|█████▊    | 1728/3000 [20:29<14:44,  1.44 examples/s]Evaluating spv_mia:  60%|█████▉    | 1792/3000 [21:16<14:15,  1.41 examples/s]Evaluating spv_mia:  62%|██████▏   | 1856/3000 [22:00<13:23,  1.42 examples/s]Evaluating spv_mia:  64%|██████▍   | 1920/3000 [22:48<12:51,  1.40 examples/s]Evaluating spv_mia:  66%|██████▌   | 1984/3000 [23:35<12:14,  1.38 examples/s]Evaluating spv_mia:  68%|██████▊   | 2048/3000 [24:19<11:15,  1.41 examples/s]Evaluating spv_mia:  70%|███████   | 2112/3000 [25:02<10:21,  1.43 examples/s]Evaluating spv_mia:  73%|███████▎  | 2176/3000 [25:48<09:40,  1.42 examples/s]Evaluating spv_mia:  75%|███████▍  | 2240/3000 [26:40<09:20,  1.36 examples/s]Evaluating spv_mia:  77%|███████▋  | 2304/3000 [27:29<08:41,  1.34 examples/s]Evaluating spv_mia:  79%|███████▉  | 2368/3000 [28:12<07:37,  1.38 examples/s]Evaluating spv_mia:  81%|████████  | 2432/3000 [28:55<06:41,  1.41 examples/s]Evaluating spv_mia:  83%|████████▎ | 2496/3000 [29:38<05:51,  1.44 examples/s]Evaluating spv_mia:  85%|████████▌ | 2560/3000 [30:27<05:15,  1.40 examples/s]Evaluating spv_mia:  87%|████████▋ | 2624/3000 [31:10<04:24,  1.42 examples/s]Evaluating spv_mia:  90%|████████▉ | 2688/3000 [31:58<03:44,  1.39 examples/s]Evaluating spv_mia:  92%|█████████▏| 2752/3000 [32:47<03:01,  1.37 examples/s]Evaluating spv_mia:  94%|█████████▍| 2816/3000 [33:36<02:16,  1.35 examples/s]Evaluating spv_mia:  96%|█████████▌| 2880/3000 [34:21<01:27,  1.37 examples/s]Evaluating spv_mia:  98%|█████████▊| 2944/3000 [35:04<00:39,  1.41 examples/s]Evaluating spv_mia: 100%|██████████| 3000/3000 [35:43<00:00,  1.41 examples/s]Evaluating spv_mia: 100%|██████████| 3000/3000 [35:43<00:00,  1.40 examples/s]
[04/17/25 06:42:53] INFO     Train avg score: -1.1951229845285416     MIA.py:144
                    INFO     Evaluating test set:                     MIA.py:155
Evaluating spv_mia:   0%|          | 0/2000 [00:00<?, ? examples/s]Evaluating spv_mia:   3%|▎         | 64/2000 [00:45<23:08,  1.39 examples/s]Evaluating spv_mia:   6%|▋         | 128/2000 [01:40<24:52,  1.25 examples/s]Evaluating spv_mia:  10%|▉         | 192/2000 [02:31<23:54,  1.26 examples/s]Evaluating spv_mia:  13%|█▎        | 256/2000 [03:16<22:01,  1.32 examples/s]Evaluating spv_mia:  16%|█▌        | 320/2000 [04:04<21:09,  1.32 examples/s]Evaluating spv_mia:  19%|█▉        | 384/2000 [04:51<20:11,  1.33 examples/s]Evaluating spv_mia:  22%|██▏       | 448/2000 [05:40<19:28,  1.33 examples/s]Evaluating spv_mia:  26%|██▌       | 512/2000 [06:28<18:41,  1.33 examples/s]Evaluating spv_mia:  29%|██▉       | 576/2000 [07:11<17:16,  1.37 examples/s]Evaluating spv_mia:  32%|███▏      | 640/2000 [07:59<16:41,  1.36 examples/s]Evaluating spv_mia:  35%|███▌      | 704/2000 [08:44<15:40,  1.38 examples/s]Evaluating spv_mia:  38%|███▊      | 768/2000 [09:33<15:09,  1.35 examples/s]Evaluating spv_mia:  42%|████▏     | 832/2000 [10:22<14:30,  1.34 examples/s]Evaluating spv_mia:  45%|████▍     | 896/2000 [11:09<13:39,  1.35 examples/s]Evaluating spv_mia:  48%|████▊     | 960/2000 [11:55<12:43,  1.36 examples/s]Evaluating spv_mia:  51%|█████     | 1024/2000 [12:48<12:25,  1.31 examples/s]Evaluating spv_mia:  54%|█████▍    | 1088/2000 [13:40<11:47,  1.29 examples/s]Evaluating spv_mia:  58%|█████▊    | 1152/2000 [14:29<10:55,  1.29 examples/s]Evaluating spv_mia:  61%|██████    | 1216/2000 [15:16<09:57,  1.31 examples/s]Evaluating spv_mia:  64%|██████▍   | 1280/2000 [16:03<09:05,  1.32 examples/s]Evaluating spv_mia:  67%|██████▋   | 1344/2000 [16:46<07:59,  1.37 examples/s]Evaluating spv_mia:  70%|███████   | 1408/2000 [17:34<07:14,  1.36 examples/s]Evaluating spv_mia:  74%|███████▎  | 1472/2000 [18:22<06:30,  1.35 examples/s]Evaluating spv_mia:  77%|███████▋  | 1536/2000 [19:10<05:44,  1.35 examples/s]Evaluating spv_mia:  80%|████████  | 1600/2000 [19:58<04:58,  1.34 examples/s]Evaluating spv_mia:  83%|████████▎ | 1664/2000 [20:42<04:04,  1.37 examples/s]Evaluating spv_mia:  86%|████████▋ | 1728/2000 [21:26<03:14,  1.40 examples/s]Evaluating spv_mia:  90%|████████▉ | 1792/2000 [22:09<02:26,  1.42 examples/s]Evaluating spv_mia:  93%|█████████▎| 1856/2000 [22:54<01:41,  1.42 examples/s]Evaluating spv_mia:  96%|█████████▌| 1920/2000 [23:45<00:58,  1.37 examples/s]Evaluating spv_mia:  99%|█████████▉| 1984/2000 [24:39<00:12,  1.31 examples/s]Evaluating spv_mia: 100%|██████████| 2000/2000 [24:55<00:00,  1.26 examples/s]Evaluating spv_mia: 100%|██████████| 2000/2000 [24:56<00:00,  1.34 examples/s]
[04/17/25 07:08:19] INFO     Test avg score: -0.6022379113584757      MIA.py:160
Saving the dataset (0/1 shards):   0%|          | 0/3000 [00:00<?, ? examples/s]Saving the dataset (0/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 22187.27 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 22187.27 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 21049.30 examples/s]
Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]Saving the dataset (1/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 23843.40 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 23103.00 examples/s]
[04/17/25 07:08:20] INFO     Neighbor data saved to                   MIA.py:279
                             ./data/neighbor_data/Qwen2TokenizerFast/           
                             ag_news/bs64/spv_mia                               
                    INFO     =========ENDING==========                 run.py:41
                    INFO                                             0 run.py:42
                             block_size                             64          
                             metric                            spv_mia          
                             train_score                     -1.195123          
                             test_score                      -0.602238          
                             acc                                0.8176          
                             auc                              0.959302          
                             TPR@0.1%FPR(0.00100)                 0.01          
                             TPR@0.5%FPR(0.00550)                0.044          
                             TPR@1.0%FPR(0.01000)             0.130667          
                             TPR@5.0%FPR(0.05000)             0.771333          
                             FPR@99.0%TPR(0.99000)               0.258          
                             FPR@95.0%TPR(0.95000)               0.125          
                             n_perturbed                            50          
                             n_neighbor                             25          
                             mask_ratio                            0.2          
                             refer_model              Qwen2ForCausalLM          
                             mask_model             RobertaForCausalLM          
                    INFO     Total time: 3727.8 seconds                run.py:45
Start running the experiment.
>>>> [CUDA]Cuda visible devices: 7
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `1`
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
[04/17/25 07:08:32] INFO     Loading model in int8: False   finetuned_llms.py:95
                             or half: True                                      
[04/17/25 07:08:33] INFO     > Loading the provided        finetuned_llms.py:113
                             ./ft_llms/Qwen/Qwen2.5-1.5B/a                      
                             g_news/bs128/target_base/chec                      
                             kpoint-279 checkpoint from                         
                             './ft_llms/Qwen/Qwen2.5-1.5B/                      
                             ag_news/bs128/target_base/che                      
                             ckpoint-279'.                                      
[04/17/25 07:08:47] INFO     Train dataset columns: ['text',     provider.py:149
                             'label'], select text column: text                 
                    INFO     Block size: 128, max buffer size:   provider.py:162
                             471859.2                                           
[04/17/25 07:08:48] INFO     Using split dataset.                  factory.py:35
Computing length of the text(train):   0%|          | 0/3000 [00:00<?, ? examples/s]Computing length of the text(train):  36%|███▌      | 1082/3000 [00:00<00:00, 10726.69 examples/s]Computing length of the text(train):  82%|████████▏ | 2463/3000 [00:00<00:00, 12529.84 examples/s]Computing length of the text(train): 100%|██████████| 3000/3000 [00:00<00:00, 10835.73 examples/s]
Computing length of the text(test):   0%|          | 0/2000 [00:00<?, ? examples/s]Computing length of the text(test):  81%|████████  | 1621/2000 [00:00<00:00, 16065.16 examples/s]Computing length of the text(test): 100%|██████████| 2000/2000 [00:00<00:00, 13441.26 examples/s]
[04/17/25 07:08:48] INFO     Average Length of the string in           run.py:20
                             dataset:(575.974, 564.36)                          
                    INFO     Data preview: {'text': "\\gunships,       run.py:21
                             pounded positions held by Shi'ite                  
                             militiamen in the\\Iraqi holy city of              
                             Najaf Thursday and large orange                    
                             multiple\\flashes lit the night sky.Iraq           
                             Oil Exports Unchanged After Basra Attack           
                             (Reuters) Reuters - Iraq's oil exports             
                             are still flowing at\\one million barrels          
                             per day through southern terminals                 
                             despite\\an attack on the South Oil                
                             Company headquarters on Thursday, an\\oil          
                             official at the company said.Canada Says           
                             G7 Not Doing Enough to Help Africa                 
                             (Reuters) Reuters - Leaders from the               
                             Group of Seven rich\\industrialized                
                             nations need to do more to aid poor                
                             African\\countries"}                               
                             {'text': ".New eggs surgery prodedure              
                             brings 20 babies, and many questions               
                             After doctors performed a kind of                  
                             transplant surgery on mothers eggs, 20             
                             babies were born to women for whom IVF             
                             had not worked.EU to Rule Tuesday on               
                             Oracle's Bid for PeopleSoft European               
                             Union regulators will decide Tuesday               
                             whether Oracle Corp.'s hostile \\$7.7              
                             billion bid for rival business software            
                             concern PeopleSoft Inc. can proceed, the           
                             EU's antitrust chief said                          
                             Friday.Americans Using Online Reputation           
                             Systems A quarter of online Americans              
                             have taken advantage of one of the                 
                             Internet's true powers: the ability to             
                             let users collectively decide whether to           
                             trust a product"}                                  
                    INFO     Loading model in int8: False   finetuned_llms.py:95
                             or half: True                                      
[04/17/25 07:08:49] INFO     > Loading the provided        finetuned_llms.py:113
                             ./ft_llms/Qwen/Qwen2.5-1.5B/a                      
                             g_news/bs128/self_prompt/chec                      
                             kpoint-168 checkpoint from                         
                             './ft_llms/Qwen/Qwen2.5-1.5B/                      
                             ag_news/bs128/self_prompt/che                      
                             ckpoint-168'.                                      
If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`
[04/17/25 07:08:53] INFO     Evaluating train set:                    MIA.py:140
Evaluating spv_mia:   0%|          | 0/3000 [00:00<?, ? examples/s]Evaluating spv_mia:   2%|▏         | 64/3000 [00:44<34:12,  1.43 examples/s]Evaluating spv_mia:   4%|▍         | 128/3000 [01:34<35:42,  1.34 examples/s]Evaluating spv_mia:   6%|▋         | 192/3000 [02:20<34:26,  1.36 examples/s]Evaluating spv_mia:   9%|▊         | 256/3000 [03:10<34:22,  1.33 examples/s]Evaluating spv_mia:  11%|█         | 320/3000 [03:57<33:12,  1.35 examples/s]Evaluating spv_mia:  13%|█▎        | 384/3000 [04:47<33:02,  1.32 examples/s]Evaluating spv_mia:  15%|█▍        | 448/3000 [05:33<31:37,  1.34 examples/s]Evaluating spv_mia:  17%|█▋        | 512/3000 [06:23<31:22,  1.32 examples/s]Evaluating spv_mia:  19%|█▉        | 576/3000 [07:08<30:00,  1.35 examples/s]Evaluating spv_mia:  21%|██▏       | 640/3000 [07:58<29:34,  1.33 examples/s]Evaluating spv_mia:  23%|██▎       | 704/3000 [08:50<29:25,  1.30 examples/s]Evaluating spv_mia:  26%|██▌       | 768/3000 [09:39<28:34,  1.30 examples/s]Evaluating spv_mia:  28%|██▊       | 832/3000 [10:30<28:09,  1.28 examples/s]Evaluating spv_mia:  30%|██▉       | 896/3000 [11:15<26:25,  1.33 examples/s]Evaluating spv_mia:  32%|███▏      | 960/3000 [12:04<25:47,  1.32 examples/s]Evaluating spv_mia:  34%|███▍      | 1024/3000 [12:53<25:06,  1.31 examples/s]Evaluating spv_mia:  36%|███▋      | 1088/3000 [13:39<23:50,  1.34 examples/s]Evaluating spv_mia:  38%|███▊      | 1152/3000 [14:25<22:44,  1.35 examples/s]Evaluating spv_mia:  41%|████      | 1216/3000 [15:11<21:46,  1.37 examples/s]Evaluating spv_mia:  43%|████▎     | 1280/3000 [16:00<21:20,  1.34 examples/s]Evaluating spv_mia:  45%|████▍     | 1344/3000 [16:51<20:56,  1.32 examples/s]Evaluating spv_mia:  47%|████▋     | 1408/3000 [17:36<19:42,  1.35 examples/s]Evaluating spv_mia:  49%|████▉     | 1472/3000 [18:25<19:05,  1.33 examples/s]Evaluating spv_mia:  51%|█████     | 1536/3000 [19:14<18:22,  1.33 examples/s]Evaluating spv_mia:  53%|█████▎    | 1600/3000 [19:58<17:06,  1.36 examples/s]Evaluating spv_mia:  55%|█████▌    | 1664/3000 [20:47<16:34,  1.34 examples/s]Evaluating spv_mia:  58%|█████▊    | 1728/3000 [21:36<15:52,  1.34 examples/s]Evaluating spv_mia:  60%|█████▉    | 1792/3000 [22:26<15:16,  1.32 examples/s]Evaluating spv_mia:  62%|██████▏   | 1856/3000 [23:11<14:11,  1.34 examples/s]Evaluating spv_mia:  64%|██████▍   | 1920/3000 [24:01<13:33,  1.33 examples/s]Evaluating spv_mia:  66%|██████▌   | 1984/3000 [24:46<12:32,  1.35 examples/s]Evaluating spv_mia:  68%|██████▊   | 2048/3000 [25:31<11:34,  1.37 examples/s]Evaluating spv_mia:  70%|███████   | 2112/3000 [26:20<10:57,  1.35 examples/s]Evaluating spv_mia:  73%|███████▎  | 2176/3000 [27:14<10:34,  1.30 examples/s]Evaluating spv_mia:  75%|███████▍  | 2240/3000 [28:04<09:46,  1.30 examples/s]Evaluating spv_mia:  77%|███████▋  | 2304/3000 [28:52<08:52,  1.31 examples/s]Evaluating spv_mia:  79%|███████▉  | 2368/3000 [29:43<08:09,  1.29 examples/s]Evaluating spv_mia:  81%|████████  | 2432/3000 [30:33<07:22,  1.28 examples/s]Evaluating spv_mia:  83%|████████▎ | 2496/3000 [31:21<06:27,  1.30 examples/s]Evaluating spv_mia:  85%|████████▌ | 2560/3000 [32:11<05:40,  1.29 examples/s]Evaluating spv_mia:  87%|████████▋ | 2624/3000 [32:59<04:47,  1.31 examples/s]Evaluating spv_mia:  90%|████████▉ | 2688/3000 [33:46<03:55,  1.33 examples/s]Evaluating spv_mia:  92%|█████████▏| 2752/3000 [34:30<03:03,  1.35 examples/s]Evaluating spv_mia:  94%|█████████▍| 2816/3000 [35:19<02:17,  1.34 examples/s]Evaluating spv_mia:  96%|█████████▌| 2880/3000 [36:09<01:30,  1.33 examples/s]Evaluating spv_mia:  98%|█████████▊| 2944/3000 [36:54<00:41,  1.35 examples/s]Evaluating spv_mia: 100%|██████████| 3000/3000 [37:37<00:00,  1.34 examples/s]Evaluating spv_mia: 100%|██████████| 3000/3000 [37:37<00:00,  1.33 examples/s]
[04/17/25 07:47:00] INFO     Train avg score: -1.400494195729494      MIA.py:144
                    INFO     Evaluating test set:                     MIA.py:155
Evaluating spv_mia:   0%|          | 0/2000 [00:00<?, ? examples/s]Evaluating spv_mia:   3%|▎         | 64/2000 [00:48<24:12,  1.33 examples/s]Evaluating spv_mia:   6%|▋         | 128/2000 [01:32<22:29,  1.39 examples/s]Evaluating spv_mia:  10%|▉         | 192/2000 [02:22<22:23,  1.35 examples/s]Evaluating spv_mia:  13%|█▎        | 256/2000 [03:09<21:29,  1.35 examples/s]Evaluating spv_mia:  16%|█▌        | 320/2000 [03:57<20:55,  1.34 examples/s]Evaluating spv_mia:  19%|█▉        | 384/2000 [04:44<19:59,  1.35 examples/s]Evaluating spv_mia:  22%|██▏       | 448/2000 [05:37<19:54,  1.30 examples/s]Evaluating spv_mia:  26%|██▌       | 512/2000 [06:32<19:47,  1.25 examples/s]Evaluating spv_mia:  29%|██▉       | 576/2000 [07:18<18:20,  1.29 examples/s]Evaluating spv_mia:  32%|███▏      | 640/2000 [08:04<17:07,  1.32 examples/s]Evaluating spv_mia:  35%|███▌      | 704/2000 [08:55<16:36,  1.30 examples/s]Evaluating spv_mia:  38%|███▊      | 768/2000 [09:45<15:54,  1.29 examples/s]Evaluating spv_mia:  42%|████▏     | 832/2000 [10:32<14:49,  1.31 examples/s]Evaluating spv_mia:  45%|████▍     | 896/2000 [11:19<13:50,  1.33 examples/s]Evaluating spv_mia:  48%|████▊     | 960/2000 [12:16<13:47,  1.26 examples/s]Evaluating spv_mia:  51%|█████     | 1024/2000 [13:08<13:01,  1.25 examples/s]Evaluating spv_mia:  54%|█████▍    | 1088/2000 [13:58<12:01,  1.26 examples/s]Evaluating spv_mia:  58%|█████▊    | 1152/2000 [14:48<11:11,  1.26 examples/s]Evaluating spv_mia:  61%|██████    | 1216/2000 [15:38<10:18,  1.27 examples/s]Evaluating spv_mia:  64%|██████▍   | 1280/2000 [16:33<09:41,  1.24 examples/s]Evaluating spv_mia:  67%|██████▋   | 1344/2000 [17:25<08:50,  1.24 examples/s]Evaluating spv_mia:  70%|███████   | 1408/2000 [18:17<08:01,  1.23 examples/s]Evaluating spv_mia:  74%|███████▎  | 1472/2000 [19:07<07:04,  1.24 examples/s]Evaluating spv_mia:  77%|███████▋  | 1536/2000 [19:57<06:08,  1.26 examples/s]Evaluating spv_mia:  80%|████████  | 1600/2000 [20:43<05:08,  1.30 examples/s]Evaluating spv_mia:  83%|████████▎ | 1664/2000 [21:35<04:23,  1.27 examples/s]Evaluating spv_mia:  86%|████████▋ | 1728/2000 [22:23<03:31,  1.29 examples/s]Evaluating spv_mia:  90%|████████▉ | 1792/2000 [23:18<02:45,  1.25 examples/s]Evaluating spv_mia:  93%|█████████▎| 1856/2000 [24:07<01:53,  1.26 examples/s]Evaluating spv_mia:  96%|█████████▌| 1920/2000 [24:58<01:03,  1.26 examples/s]Evaluating spv_mia:  99%|█████████▉| 1984/2000 [25:47<00:12,  1.27 examples/s]Evaluating spv_mia: 100%|██████████| 2000/2000 [26:03<00:00,  1.25 examples/s]Evaluating spv_mia: 100%|██████████| 2000/2000 [26:03<00:00,  1.28 examples/s]
[04/17/25 08:13:32] INFO     Test avg score: -1.0427176775038243      MIA.py:160
Saving the dataset (0/1 shards):   0%|          | 0/3000 [00:00<?, ? examples/s]Saving the dataset (1/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 32319.15 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 31002.02 examples/s]
Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]Saving the dataset (1/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 21373.23 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 20799.15 examples/s]
[04/17/25 08:13:33] INFO     Neighbor data saved to                   MIA.py:279
                             ./data/neighbor_data/Qwen2TokenizerFast/           
                             ag_news/bs128/spv_mia                              
                    INFO     =========ENDING==========                 run.py:41
                    INFO                                             0 run.py:42
                             block_size                            128          
                             metric                            spv_mia          
                             train_score                     -1.400494          
                             test_score                      -1.042718          
                             acc                                0.6122          
                             auc                              0.698555          
                             TPR@0.1%FPR(0.00100)             0.006333          
                             TPR@0.5%FPR(0.00500)                0.012          
                             TPR@1.0%FPR(0.01050)             0.018667          
                             TPR@5.0%FPR(0.05050)             0.230333          
                             FPR@99.0%TPR(0.99000)              0.8385          
                             FPR@95.0%TPR(0.95000)              0.7595          
                             n_perturbed                            20          
                             n_neighbor                             25          
                             mask_ratio                            0.2          
                             refer_model              Qwen2ForCausalLM          
                             mask_model             RobertaForCausalLM          
                    INFO     Total time: 3900.8 seconds                run.py:45
Start running the experiment.
>>>> [CUDA]Cuda visible devices: 7
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `1`
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
[04/17/25 08:13:49] INFO     Loading model in int8: False   finetuned_llms.py:95
                             or half: True                                      
                    INFO     > Loading the provided        finetuned_llms.py:113
                             ./ft_llms/Qwen/Qwen2.5-1.5B/a                      
                             g_news/bs128/target_base/chec                      
                             kpoint-279 checkpoint from                         
                             './ft_llms/Qwen/Qwen2.5-1.5B/                      
                             ag_news/bs128/target_base/che                      
                             ckpoint-279'.                                      
[04/17/25 08:14:05] INFO     Train dataset columns: ['text',     provider.py:149
                             'label'], select text column: text                 
                    INFO     Block size: 128, max buffer size:   provider.py:162
                             471859.2                                           
[04/17/25 08:14:05] INFO     Using split dataset.                  factory.py:35
Computing length of the text(train):   0%|          | 0/3000 [00:00<?, ? examples/s]Computing length of the text(train):  49%|████▊     | 1460/3000 [00:00<00:00, 14522.80 examples/s]Computing length of the text(train): 100%|██████████| 3000/3000 [00:00<00:00, 13194.19 examples/s]Computing length of the text(train): 100%|██████████| 3000/3000 [00:00<00:00, 12813.91 examples/s]
Computing length of the text(test):   0%|          | 0/2000 [00:00<?, ? examples/s]Computing length of the text(test):  50%|█████     | 1000/2000 [00:00<00:00, 9762.28 examples/s]Computing length of the text(test): 100%|██████████| 2000/2000 [00:00<00:00, 11370.30 examples/s]
[04/17/25 08:14:05] INFO     Average Length of the string in           run.py:20
                             dataset:(575.974, 564.36)                          
                    INFO     Data preview: {'text': "\\gunships,       run.py:21
                             pounded positions held by Shi'ite                  
                             militiamen in the\\Iraqi holy city of              
                             Najaf Thursday and large orange                    
                             multiple\\flashes lit the night sky.Iraq           
                             Oil Exports Unchanged After Basra Attack           
                             (Reuters) Reuters - Iraq's oil exports             
                             are still flowing at\\one million barrels          
                             per day through southern terminals                 
                             despite\\an attack on the South Oil                
                             Company headquarters on Thursday, an\\oil          
                             official at the company said.Canada Says           
                             G7 Not Doing Enough to Help Africa                 
                             (Reuters) Reuters - Leaders from the               
                             Group of Seven rich\\industrialized                
                             nations need to do more to aid poor                
                             African\\countries"}                               
                             {'text': ".New eggs surgery prodedure              
                             brings 20 babies, and many questions               
                             After doctors performed a kind of                  
                             transplant surgery on mothers eggs, 20             
                             babies were born to women for whom IVF             
                             had not worked.EU to Rule Tuesday on               
                             Oracle's Bid for PeopleSoft European               
                             Union regulators will decide Tuesday               
                             whether Oracle Corp.'s hostile \\$7.7              
                             billion bid for rival business software            
                             concern PeopleSoft Inc. can proceed, the           
                             EU's antitrust chief said                          
                             Friday.Americans Using Online Reputation           
                             Systems A quarter of online Americans              
                             have taken advantage of one of the                 
                             Internet's true powers: the ability to             
                             let users collectively decide whether to           
                             trust a product"}                                  
                    INFO     Loading model in int8: False   finetuned_llms.py:95
                             or half: True                                      
[04/17/25 08:14:06] INFO     > Loading the provided        finetuned_llms.py:113
                             ./ft_llms/Qwen/Qwen2.5-1.5B/a                      
                             g_news/bs128/self_prompt/chec                      
                             kpoint-168 checkpoint from                         
                             './ft_llms/Qwen/Qwen2.5-1.5B/                      
                             ag_news/bs128/self_prompt/che                      
                             ckpoint-168'.                                      
If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`
[04/17/25 08:14:10] INFO     Evaluating train set:                    MIA.py:140
Evaluating spv_mia:   0%|          | 0/3000 [00:00<?, ? examples/s]Evaluating spv_mia:   2%|▏         | 64/3000 [01:49<1:24:06,  1.72s/ examples]Evaluating spv_mia:   4%|▍         | 128/3000 [03:46<1:25:06,  1.78s/ examples]Evaluating spv_mia:   6%|▋         | 192/3000 [05:49<1:26:11,  1.84s/ examples]Evaluating spv_mia:   9%|▊         | 256/3000 [07:50<1:25:19,  1.87s/ examples]Evaluating spv_mia:  11%|█         | 320/3000 [09:42<1:21:18,  1.82s/ examples]Evaluating spv_mia:  13%|█▎        | 384/3000 [11:46<1:21:04,  1.86s/ examples]Evaluating spv_mia:  15%|█▍        | 448/3000 [13:38<1:17:36,  1.82s/ examples]Evaluating spv_mia:  17%|█▋        | 512/3000 [15:39<1:16:30,  1.85s/ examples]Evaluating spv_mia:  19%|█▉        | 576/3000 [17:27<1:12:37,  1.80s/ examples]Evaluating spv_mia:  21%|██▏       | 640/3000 [19:29<1:11:55,  1.83s/ examples]Evaluating spv_mia:  23%|██▎       | 704/3000 [21:29<1:10:38,  1.85s/ examples]Evaluating spv_mia:  26%|██▌       | 768/3000 [23:15<1:06:25,  1.79s/ examples]Evaluating spv_mia:  28%|██▊       | 832/3000 [25:15<1:05:36,  1.82s/ examples]Evaluating spv_mia:  30%|██▉       | 896/3000 [27:10<1:03:23,  1.81s/ examples]Evaluating spv_mia:  32%|███▏      | 960/3000 [29:10<1:02:06,  1.83s/ examples]Evaluating spv_mia:  34%|███▍      | 1024/3000 [31:08<1:00:26,  1.84s/ examples]Evaluating spv_mia:  36%|███▋      | 1088/3000 [32:55<56:55,  1.79s/ examples]  Evaluating spv_mia:  38%|███▊      | 1152/3000 [34:42<53:53,  1.75s/ examples]Evaluating spv_mia:  41%|████      | 1216/3000 [36:31<51:42,  1.74s/ examples]Evaluating spv_mia:  43%|████▎     | 1280/3000 [38:29<50:39,  1.77s/ examples]Evaluating spv_mia:  45%|████▍     | 1344/3000 [40:27<49:27,  1.79s/ examples]Evaluating spv_mia:  47%|████▋     | 1408/3000 [42:13<46:29,  1.75s/ examples]Evaluating spv_mia:  49%|████▉     | 1472/3000 [44:11<45:14,  1.78s/ examples]Evaluating spv_mia:  51%|█████     | 1536/3000 [46:06<43:28,  1.78s/ examples]Evaluating spv_mia:  53%|█████▎    | 1600/3000 [47:51<40:38,  1.74s/ examples]Evaluating spv_mia:  55%|█████▌    | 1664/3000 [49:44<38:56,  1.75s/ examples]Evaluating spv_mia:  58%|█████▊    | 1728/3000 [51:30<36:28,  1.72s/ examples]Evaluating spv_mia:  60%|█████▉    | 1792/3000 [53:25<35:08,  1.75s/ examples]Evaluating spv_mia:  62%|██████▏   | 1856/3000 [55:12<32:51,  1.72s/ examples]Evaluating spv_mia:  64%|██████▍   | 1920/3000 [57:12<31:48,  1.77s/ examples]Evaluating spv_mia:  66%|██████▌   | 1984/3000 [59:03<29:46,  1.76s/ examples]Evaluating spv_mia:  68%|██████▊   | 2048/3000 [1:00:53<27:39,  1.74s/ examples]Evaluating spv_mia:  70%|███████   | 2112/3000 [1:02:50<26:12,  1.77s/ examples]Evaluating spv_mia:  73%|███████▎  | 2176/3000 [1:04:58<25:15,  1.84s/ examples]Evaluating spv_mia:  75%|███████▍  | 2240/3000 [1:06:55<23:16,  1.84s/ examples]Evaluating spv_mia:  77%|███████▋  | 2304/3000 [1:08:52<21:15,  1.83s/ examples]Evaluating spv_mia:  79%|███████▉  | 2368/3000 [1:10:45<19:07,  1.82s/ examples]Evaluating spv_mia:  81%|████████  | 2432/3000 [1:12:45<17:19,  1.83s/ examples]Evaluating spv_mia:  83%|████████▎ | 2496/3000 [1:14:33<15:01,  1.79s/ examples]Evaluating spv_mia:  85%|████████▌ | 2560/3000 [1:16:30<13:12,  1.80s/ examples]Evaluating spv_mia:  87%|████████▋ | 2624/3000 [1:18:19<11:05,  1.77s/ examples]Evaluating spv_mia:  90%|████████▉ | 2688/3000 [1:20:08<09:06,  1.75s/ examples]Evaluating spv_mia:  92%|█████████▏| 2752/3000 [1:22:01<07:15,  1.76s/ examples]Evaluating spv_mia:  94%|█████████▍| 2816/3000 [1:24:04<05:31,  1.80s/ examples]Evaluating spv_mia:  96%|█████████▌| 2880/3000 [1:26:07<03:41,  1.84s/ examples]Evaluating spv_mia:  98%|█████████▊| 2944/3000 [1:27:57<01:41,  1.80s/ examples]Evaluating spv_mia: 100%|██████████| 3000/3000 [1:29:41<00:00,  1.82s/ examples]Evaluating spv_mia: 100%|██████████| 3000/3000 [1:29:41<00:00,  1.79s/ examples]
[04/17/25 09:44:23] INFO     Train avg score: -1.635629015872876      MIA.py:144
                    INFO     Evaluating test set:                     MIA.py:155
Evaluating spv_mia:   0%|          | 0/2000 [00:00<?, ? examples/s]Evaluating spv_mia:   3%|▎         | 64/2000 [01:57<59:25,  1.84s/ examples]Evaluating spv_mia:   6%|▋         | 128/2000 [03:49<55:34,  1.78s/ examples]Evaluating spv_mia:  10%|▉         | 192/2000 [05:50<55:13,  1.83s/ examples]Evaluating spv_mia:  13%|█▎        | 256/2000 [07:41<52:12,  1.80s/ examples]Evaluating spv_mia:  16%|█▌        | 320/2000 [09:39<50:45,  1.81s/ examples]Evaluating spv_mia:  19%|█▉        | 384/2000 [11:31<48:12,  1.79s/ examples]Evaluating spv_mia:  22%|██▏       | 448/2000 [13:31<47:00,  1.82s/ examples]Evaluating spv_mia:  26%|██▌       | 512/2000 [15:39<46:35,  1.88s/ examples]Evaluating spv_mia:  29%|██▉       | 576/2000 [17:31<43:31,  1.83s/ examples]Evaluating spv_mia:  32%|███▏      | 640/2000 [19:23<40:59,  1.81s/ examples]Evaluating spv_mia:  35%|███▌      | 704/2000 [21:22<39:26,  1.83s/ examples]Evaluating spv_mia:  38%|███▊      | 768/2000 [23:27<38:17,  1.86s/ examples]Evaluating spv_mia:  42%|████▏     | 832/2000 [25:18<35:29,  1.82s/ examples]Evaluating spv_mia:  45%|████▍     | 896/2000 [27:10<33:11,  1.80s/ examples]Evaluating spv_mia:  48%|████▊     | 960/2000 [29:23<32:42,  1.89s/ examples]Evaluating spv_mia:  51%|█████     | 1024/2000 [31:22<30:32,  1.88s/ examples]Evaluating spv_mia:  54%|█████▍    | 1088/2000 [33:21<28:26,  1.87s/ examples]Evaluating spv_mia:  58%|█████▊    | 1152/2000 [35:20<26:25,  1.87s/ examples]Evaluating spv_mia:  61%|██████    | 1216/2000 [37:20<24:24,  1.87s/ examples]Evaluating spv_mia:  64%|██████▍   | 1280/2000 [39:33<23:11,  1.93s/ examples]Evaluating spv_mia:  67%|██████▋   | 1344/2000 [41:40<21:16,  1.95s/ examples]Evaluating spv_mia:  70%|███████   | 1408/2000 [43:41<19:02,  1.93s/ examples]Evaluating spv_mia:  74%|███████▎  | 1472/2000 [45:38<16:44,  1.90s/ examples]Evaluating spv_mia:  77%|███████▋  | 1536/2000 [47:38<14:39,  1.89s/ examples]Evaluating spv_mia:  80%|████████  | 1600/2000 [49:34<12:26,  1.87s/ examples]Evaluating spv_mia:  83%|████████▎ | 1664/2000 [51:47<10:48,  1.93s/ examples]Evaluating spv_mia:  86%|████████▋ | 1728/2000 [53:58<08:54,  1.97s/ examples]Evaluating spv_mia:  90%|████████▉ | 1792/2000 [56:11<06:56,  2.00s/ examples]Evaluating spv_mia:  93%|█████████▎| 1856/2000 [58:17<04:46,  1.99s/ examples]Evaluating spv_mia:  96%|█████████▌| 1920/2000 [1:00:17<02:36,  1.95s/ examples]Evaluating spv_mia:  99%|█████████▉| 1984/2000 [1:02:25<00:31,  1.97s/ examples]Evaluating spv_mia: 100%|██████████| 2000/2000 [1:02:56<00:00,  1.97s/ examples]Evaluating spv_mia: 100%|██████████| 2000/2000 [1:02:57<00:00,  1.89s/ examples]
[04/17/25 10:47:52] INFO     Test avg score: -1.2927223698198795      MIA.py:160
Saving the dataset (0/1 shards):   0%|          | 0/3000 [00:00<?, ? examples/s]Saving the dataset (0/1 shards):  33%|███▎      | 1000/3000 [00:00<00:00, 9000.32 examples/s]Saving the dataset (0/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 12767.29 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 12767.29 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 3000/3000 [00:00<00:00, 11791.79 examples/s]
Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]Saving the dataset (0/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 15323.53 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 15323.53 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 2000/2000 [00:00<00:00, 14412.99 examples/s]
[04/17/25 10:47:55] INFO     Neighbor data saved to                   MIA.py:279
                             ./data/neighbor_data/Qwen2TokenizerFast/           
                             ag_news/bs128/spv_mia                              
[04/17/25 10:47:57] INFO     =========ENDING==========                 run.py:41
                    INFO                                             0 run.py:42
                             block_size                            128          
                             metric                            spv_mia          
                             train_score                     -1.635629          
                             test_score                      -1.292722          
                             acc                                0.6488          
                             auc                              0.724222          
                             TPR@0.1%FPR(0.00100)             0.005333          
                             TPR@0.5%FPR(0.00500)             0.011667          
                             TPR@1.0%FPR(0.01000)             0.017333          
                             TPR@5.0%FPR(0.05000)             0.231333          
                             FPR@99.0%TPR(0.99000)               0.905          
                             FPR@95.0%TPR(0.94933)               0.848          
                             n_perturbed                            50          
                             n_neighbor                             25          
                             mask_ratio                            0.2          
                             refer_model              Qwen2ForCausalLM          
                             mask_model             RobertaForCausalLM          
                    INFO     Total time: 9248.1 seconds                run.py:45
